{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted rating of user $u$ on item $i$,\n",
    "\n",
    "$$\\hat{r}_{ui}=U_u.V_{i.}^T+b_i$$\n",
    "\n",
    "\n",
    "The Bernoulli distribution of binary random variable $\\delta((u,i)\\succ(u,j))$ is\n",
    "\n",
    "defined as follows[Rendle et al., 2009],\n",
    "\n",
    "$$\\begin{aligned}\\mathrm{LPP}_{u}&=\\quad\\prod_{i,j\\in\\mathcal{I}}Pr(\\hat{r}_{ui}>\\hat{r}_{uj})^{\\delta((u,i)\\succ(u,j))}[1-Pr(\\hat{r}_{ui}>\\hat{r}_{uj})]^{[1-\\delta(u,i)\\succ(u,j)}\\\\&=\\quad\\prod_{(u,i)\\succ(u,j)}Pr(\\hat{r}_{ui}>\\hat{r}_{uj})\\times\\prod_{(u,i)\\preceq(u,j)}[1-Pr(\\hat{r}_{ui}>\\hat{r}_{uj})]\\end{aligned}$$\n",
    "\n",
    "where $(u,i)\\succ(u,j)$ means that user $u$ prefers item $i$ to item $j.$\n",
    "\n",
    "$$\\begin{aligned}InLPP_u&=\\quad\\ln\\prod_{(u,i)\\succ(u,j)}\\sigma(\\hat{r}_{uij})+\\ln\\prod_{(u,i)\\preceq(u,j)}[1-\\sigma(\\hat{r}_{uij})]\\\\&\\approx\\ln\\prod_{(u,i)\\succ(u,j)}\\sigma(\\hat{r}_{uij})+\\ln\\prod_{(u,i)\\succ(u,j)}[1-\\sigma(-\\hat{r}_{uij})]\\\\&=\\quad\\ln\\prod_{(u,i)\\succ(u,j)}\\sigma(\\hat{r}_{uij})+\\ln\\prod_{(u,i)\\succ(u,j)}\\sigma(\\hat{r}_{uij})\\\\&=2\\sum_{(u,i)\\succ(u,j)}\\ln\\sigma(\\hat{r}_{uij})\\\\&=2\\sum_{i\\in\\mathcal{I}_u}\\sum_{j\\in\\mathcal{I}\\setminus\\mathcal{I}_u}\\ln\\sigma(\\hat{r}_{uij})\\end{aligned}$$\n",
    "\n",
    "Objective function,\n",
    "\n",
    "$$\\min_\\Theta\\sum_{u\\in\\mathcal{U}}\\sum_{i\\in\\mathcal{I}_u}\\sum_{j\\in\\mathcal{I}\\setminus\\mathcal{I}_u}f_{uij}$$\n",
    "\n",
    "where\n",
    "$f_{uij}=-\\ln\\sigma(\\hat{r}_{uij})+\\frac{\\alpha_u}2\\|U_u.\\|^2+\\frac{\\alpha_v}2\\|V_i.\\|^2+\\frac{\\alpha_v}2\\|V_j.\\|^2+\\frac{\\beta_v}2\\|b_i\\|^2+\\frac{\\beta_v}2\\|b_j\\|^2$ and$\\Theta = \\{ U_u. , u= 1, 2, \\ldots , n; V_i. , b_i, i= 1, 2, \\ldots , m\\}$ denotes the set of\n",
    "\n",
    "parameters to be learned.\n",
    "\n",
    "\n",
    "$$\\begin{aligned}&\\nabla U_{u}.&&=\\frac{\\partial f_{uij}}{\\partial U_u.}=-\\sigma(-\\hat{r}_{uij})(V_i.-V_{j.})+\\alpha_uU_u.,\\\\&\\nabla V_{i.}&&=\\frac{\\partial f_{uij}}{\\partial V_i.}=-\\sigma(-\\hat{r}_{uij})U_{u.}+\\alpha_vV_{i.},\\\\&\\nabla V_{j.}&&=\\frac{\\partial f_{uij}}{\\partial V_{j.}}=-\\sigma(-\\hat{r}_{uij})(-U_{u.\\cdot})+\\alpha_vV_{j.},\\\\&\\nabla b_{i}&&=\\frac{\\partial f_{uij}}{\\partial b_i}=-\\sigma(-\\hat{r}_{uij})+\\beta_vb_i,\\\\&\\nabla b_{j}&&=\\frac{\\partial f_{uij}}{\\partial b_j}=-\\sigma(-\\hat{r}_{uij})(-1)+\\beta_vb_j,\\end{aligned}$$\n",
    "\n",
    "For a randomly sampled triple $(u,i,j)$, we have the update rules,\n",
    "\n",
    "$$U_u.=\\quad U_u.-\\gamma\\nabla U_u.,\\\\V_i.=\\quad V_i.-\\gamma\\nabla V_i.,\\\\V_j.=\\quad V_j.-\\gamma\\nabla V_j.,\\\\b_i=\\quad b_i-\\gamma\\nabla b_i,\\\\b_j=\\quad b_j-\\gamma\\nabla b_j,$$\n",
    "\n",
    "where $\\gamma$ is the learning rate.\n",
    "\n",
    "Pre-processing (for simulation): we only keep the (user, item) pairs with ratings 4 or 5 in u1.base and u1.test as preferred (user,item) pairs, and remove all other records. Finally, we obtain u1.base.OCCF and u1.test.OCCF.\n",
    "\n",
    "Pre@5: The precision of user $u$ is defined as,\n",
    "$$\\mathrm{Pre}_u@k=\\frac1k\\sum_{\\ell=1}^k\\delta(i(\\ell)\\in\\mathcal{I}_u^{te}),$$\n",
    "\n",
    "where $\\delta(x)=1$ if $x$ is true and $\\delta(x)=0$ otherwise. Then, we have\n",
    "\n",
    "$Pre@k=\\sum_{u\\in\\mathcal{U}^{te}}Pre_u\\otimes k/|U^{te}|.$\n",
    "\n",
    "Rec@5: The recall of user $u$ is defined as,\n",
    "\n",
    "$$\\mathrm{Rec}_u@k=\\frac1{|\\mathcal{I}_u^{te}|}\\sum_{\\ell=1}^k\\delta(\\mathrm{i}(\\ell)\\in\\mathcal{I}_u^{te}),$$\n",
    "\n",
    "which means how many preferred items are recommended in the top-k list. Then, we have $Rec@k=\\sum_{u\\in\\mathcal{U}^{te}}Rec_u@k/|U^{te}|.$\n",
    "\n",
    "We use the files u1.base and u1.test of MovieLens100K1 as our\n",
    "training data and test data, respectively. user number: n = 943; item number: m = 1682.\n",
    "u1.base (training data): 80000 rating records, and the density (or\n",
    "sparsity) is 80000/943/1682 = 5.04%.\n",
    "u1.test (test data): 20000 rating records.\n",
    "Pre-processing (for simulation): we only keep the (user, item) pairs with ratings 4 or 5 in u1.base and u1.test as preferred (user,item) pairs, and remove all other records. Finally, we obtain u1.base.OCCF and u1.test.OCCF.\n",
    "\n",
    "$$\\begin{aligned}&\\text{We fix }\\gamma=0.01,\\text{and search the best values of the following}\\\\&\\text{parameters,}\\\\&\\bullet\\alpha_{u}=\\alpha_{v}=\\beta_{v}\\in\\{0.001,0.01,0.1\\}\\\\&\\bullet T\\in\\{100,500,1000\\}\\\\&\\bullet d=20\\\\&\\mathrm{Finally,~we~use~}\\gamma=0.01,\\alpha_{u}=\\alpha_{v}=\\beta_{v}=0.01,T=500\\mathrm{~and~}d=20.\\end{aligned}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ！/usr/bin/env python\n",
    "# @Time:2021/4/6 19:21\n",
    "# @Author:华阳\n",
    "# @File:Basical BPR.py\n",
    "# @Software:PyCharm\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scores\n",
    "'''\n",
    "函数说明:BPR类（包含所需的各种参数）\n",
    "Parameters:\n",
    "    无\n",
    "Returns:\n",
    "    无\n",
    "'''\n",
    "class BPR:\n",
    "    #用户数\n",
    "    user_count = 943\n",
    "    #项目数\n",
    "    item_count = 1682\n",
    "    #k个主题,k数\n",
    "    latent_fact,rs = 20\n",
    "    #步长α\n",
    "    lr = 0.01\n",
    "    #参数λ\n",
    "    reg = 0.01\n",
    "    #训练次数\n",
    "    train_count = 10000\n",
    "    #训练集\n",
    "    train_data_path = 'train.txt'\n",
    "    #测试集\n",
    "    test_data_path = 'test.txt'\n",
    "    #U-I的大小\n",
    "    size_u_i = user_count * item_count\n",
    "    # 随机设定的U，V矩阵(即公式中的Wuk和Hik)矩阵\n",
    "    U = np.random.rand(user_count, latent_factors) * 0.01 #大小无所谓\n",
    "    V = np.random.rand(item_count, latent_factors) * 0.01\n",
    "    biasV = np.random.rand(item_count) * 0.01\n",
    "    #生成一个用户数*项目数大小的全0矩阵\n",
    "    test_data = np.zeros((user_count, item_count))\n",
    "    print(\"test_data_type\",type(test_data))\n",
    "    #生成一个一维的全0矩阵\n",
    "    test = np.zeros(size_u_i)\n",
    "    #再生成一个一维的全0矩阵\n",
    "    predict_ = np.zeros(size_u_i)\n",
    "\n",
    "    #获取U-I数据对应\n",
    "    '''\n",
    "    函数说明：通过文件路径，获取U-I数据\n",
    "    Paramaters:\n",
    "        输入要读入的文件路径path\n",
    "    Returns:\n",
    "        输出一个字典user_ratings，包含用户-项目的键值对\n",
    "    '''\n",
    "    def load_data(self, path):\n",
    "        user_ratings = defaultdict(set)\n",
    "        with open(path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                u, i = line.split(\" \")\n",
    "                u = int(u)\n",
    "                i = int(i)\n",
    "                user_ratings[u].add(i)\n",
    "        return user_ratings\n",
    "    '''\n",
    "    函数说明：通过文件路径，获取测试集数据\n",
    "    Paramaters：\n",
    "        测试集文件路径path\n",
    "    Returns:\n",
    "        输出一个numpy.ndarray文件（n维数组）test_data,其中把含有反馈信息的数据置为1\n",
    "    '''\n",
    "    #获取测试集的评分矩阵\n",
    "    def load_test_data(self, path):\n",
    "        file = open(path, 'r')\n",
    "        for line in file:\n",
    "            line = line.split(' ')\n",
    "            user = int(line[0])\n",
    "            item = int(line[1])\n",
    "            self.test_data[user - 1][item - 1] = 1\n",
    "    '''\n",
    "    函数说明：对训练集数据字典处理，通过随机选取，（用户，交互，为交互）三元组，更新分解后的两个矩阵\n",
    "    Parameters：\n",
    "        输入要处理的训练集用户项目字典\n",
    "    Returns：\n",
    "        对分解后的两个矩阵以及偏置矩阵分别更新\n",
    "    '''\n",
    "    def train(self, user_ratings_train):\n",
    "        for user in range(self.user_count):\n",
    "            # 随机获取一个用户\n",
    "            u = random.randint(1, self.user_count) #找到一个user\n",
    "            # 训练集和测试集的用于不是全都一样的,比如train有948,而test最大为943\n",
    "            if u not in user_ratings_train.keys():\n",
    "                continue\n",
    "            # 从用户的U-I中随机选取1个Item\n",
    "            i = random.sample(user_ratings_train[u], 1)[0] #找到一个item，被评分\n",
    "            # 随机选取一个用户u没有评分的项目\n",
    "            j = random.randint(1, self.item_count)\n",
    "            while j in user_ratings_train[u]:\n",
    "                j = random.randint(1, self.item_count) #找到一个item，没有被评分\n",
    "            #构成一个三元组（uesr,item_have_score,item_no_score)\n",
    "            # python中的取值从0开始\n",
    "            u = u - 1\n",
    "            i = i - 1\n",
    "            j = j,- 1\n",
    "            #BPR\n",
    "            r_ui = np.dot(self.U[u], self.V[i].T) + self.biasV[i]\n",
    "            r_uj = np.dot(self.U[u], self.V[j].T) + self.biasV[j]\n",
    "            r_uij = r_ui - r_uj\n",
    "            loss_func = -1.0 / (1 + np.exp(r_uij))\n",
    "            # 更新2个矩阵\n",
    "            self.U[u] += -self.lr * (loss_func * (self.V[i] - self.V[j]) + self.reg * self.U[u])\n",
    "            self.V[i] += -self.lr * (loss_func * self.U[u] + self.reg * self.V[i])\n",
    "            self.V[j] += -self.lr * (loss_func * (-self.U[u]) + self.reg * self.V[j])\n",
    "            # 更新偏置项\n",
    "            self.biasV[i] += -self.lr * (loss_func + self.reg * self.biasV[i])\n",
    "            self.biasV[j] += -self.lr * (-loss_func + self.reg * self.biasV[j])\n",
    "    '''\n",
    "    函数说明：通过输入分解后的用户项目矩阵得到预测矩阵predict\n",
    "    Parameters:\n",
    "        输入分别后的用户项目矩阵\n",
    "    Returns：\n",
    "        输出相乘后的预测矩阵，即我们所要的评分矩阵\n",
    "    '''\n",
    "    def predict(self, user, item):\n",
    "        predict = np.mat(user) * np.mat(item.T)\n",
    "        return predict\n",
    "\n",
    "    #主函数\n",
    "    def main(self):\n",
    "        #获取U-I的{1:{2,5,1,2}....}数据\n",
    "        user_ratings_train = self.load_data(self.train_data_path)\n",
    "        #获取测试集的评分矩阵\n",
    "        self.load_test_data(self.test_data_path)\n",
    "        #将test_data矩阵拍平\n",
    "        for u in range(self.user_count):\n",
    "            for item in range(self.item_count):\n",
    "                if int(self.test_data[u][item]) == 1:\n",
    "                    self.test[u * self.item_count + item] = 1\n",
    "                else:\n",
    "                    self.test[u * self.item_count + item] = 0\n",
    "        #训练\n",
    "        for i in range(self.train_count):\n",
    "            self.train(user_ratings_train)  #训练10000次完成\n",
    "        predict_matrix = self.predict(self.U, self.V) #将训练完成的矩阵內积\n",
    "        # 预测\n",
    "        self.predict_ = predict_matrix.getA().reshape(-1)  #.getA()将自身矩阵变量转化为ndarray类型的变量\n",
    "        print(\"predict_new\",self.predict_)\n",
    "        self.predict_ = pre_handel(user_ratings_train, self.predict_, self.item_count)\n",
    "        auc_score = roc_auc_score(self.test, self.predict_)\n",
    "        print('AUC:', auc_score)\n",
    "        # Top-K evaluation\n",
    "        scores.topK_scores(self.test, self.predict_, 5, self.user_count, self.item_count)\n",
    "    '''\n",
    "    函数说明：对结果进行修正，即用户已经产生交互的用户项目进行剔除，只保留没有产生用户项目的交互的数据\n",
    "    Paramaters:\n",
    "        输入用户项目字典集，以及一维的预测矩阵，项目个数\n",
    "    Returns:\n",
    "        输出修正后的预测评分一维的预测矩阵\n",
    "    '''\n",
    "def pre_handel(set, predict, item_count):\n",
    "    # Ensure the recommendation cannot be positive items in the training set.\n",
    "    for u in set.keys():\n",
    "        for j in set[u]:\n",
    "            predict[(u - 1) * item_count + j - 1] = 0\n",
    "    return predict\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #调用类的主函数\n",
    "    bpr = BPR()\n",
    "    bpr.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n",
      "完成迭代 100/500\n",
      "完成迭代 200/500\n",
      "完成迭代 300/500\n",
      "完成迭代 400/500\n",
      "完成迭代 500/500\n",
      "Precision@5: 0.2100\n",
      "Recall@5: 0.1441\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "\n",
    "class BPR:\n",
    "    def __init__(self, user_count=943, item_count=1682):\n",
    "        # 模型参数\n",
    "        self.user_count = user_count      \n",
    "        self.item_count = item_count      \n",
    "        self.factors = 20                 # d = 20\n",
    "        self.gamma = 0.01                 # γ = 0.01\n",
    "        self.alpha_u = 0.01              # αu = 0.01\n",
    "        self.alpha_v = 0.01              # αv = 0.01\n",
    "        self.beta_v = 0.01               # βv = 0.01\n",
    "        self.iterations = 500            # T = 500\n",
    "        \n",
    "        # 初始化模型参数\n",
    "        self.U = np.random.uniform(-0.01, 0.01, (user_count + 1, self.factors))\n",
    "        self.V = np.random.uniform(-0.01, 0.01, (item_count + 1, self.factors))\n",
    "        self.bias_V = np.zeros(item_count + 1)\n",
    "        \n",
    "        # 记录训练数据\n",
    "        self.item_set_whole = set()        # 所有评分物品集合\n",
    "        self.initial_item_set = set()      # 所有正例物品集合\n",
    "        self.num_train = 0                 # 训练数据量\n",
    "        self.item_rating_train = np.zeros(item_count + 1)  # 物品评分数\n",
    "\n",
    "    def load_data(self, filename, rating_threshold=5.0):\n",
    "        \"\"\"加载数据，只保留评分等于阈值的交互\"\"\"\n",
    "        user_list = []\n",
    "        item_list = []\n",
    "        initial_train_data = defaultdict(set)\n",
    "        \n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                u, i, r = map(float, line.strip().split('\\t')[:3])\n",
    "                u, i = int(u), int(i)\n",
    "                \n",
    "                # 记录所有交互\n",
    "                self.initial_item_set.add(i)\n",
    "                initial_train_data[u].add(i)\n",
    "                \n",
    "                # 只保留评分为5的正例\n",
    "                if r == rating_threshold:\n",
    "                    user_list.append(u)\n",
    "                    item_list.append(i)\n",
    "                    self.item_set_whole.add(i)\n",
    "                    self.item_rating_train[i] += 1\n",
    "                    self.num_train += 1\n",
    "        \n",
    "        # 计算物品偏置\n",
    "        g_avg = np.sum(self.item_rating_train) / (self.user_count * self.item_count)\n",
    "        self.bias_V = self.item_rating_train / self.user_count - g_avg\n",
    "            \n",
    "        return user_list, item_list, initial_train_data\n",
    "\n",
    "    def train(self, train_data):\n",
    "        \"\"\"训练BPR模型\"\"\"\n",
    "        print(\"开始训练...\")\n",
    "        for iteration in range(self.iterations):\n",
    "            # 对每个训练样本进行采样\n",
    "            for _ in range(self.num_train):\n",
    "                # 随机采样索引获取用户和正例物品\n",
    "                idx = random.randint(0, self.num_train - 1)\n",
    "                u = random.randint(1, self.user_count)\n",
    "                if u not in train_data:\n",
    "                    continue\n",
    "                    \n",
    "                i = random.choice(list(train_data[u]))\n",
    "                \n",
    "                # 采样负例物品\n",
    "                while True:\n",
    "                    j = random.randint(1, self.item_count)\n",
    "                    if j in self.item_set_whole and j not in train_data[u]:\n",
    "                        break\n",
    "                \n",
    "                # 计算预测差值\n",
    "                r_uij = self.bias_V[i] - self.bias_V[j]\n",
    "                for f in range(self.factors):\n",
    "                    r_uij += self.U[u][f] * (self.V[i][f] - self.V[j][f])\n",
    "                \n",
    "                # 计算梯度\n",
    "                exp_r_uij = np.exp(r_uij)\n",
    "                loss_uij = -1.0 / (1.0 + exp_r_uij)\n",
    "                \n",
    "                # 更新用户和物品向量\n",
    "                for f in range(self.factors):\n",
    "                    grad_u_f = loss_uij * (self.V[i][f] - self.V[j][f]) + self.alpha_u * self.U[u][f]\n",
    "                    grad_i_f = loss_uij * self.U[u][f] + self.alpha_v * self.V[i][f]\n",
    "                    grad_j_f = loss_uij * (-self.U[u][f]) + self.alpha_v * self.V[j][f]\n",
    "                    \n",
    "                    self.U[u][f] -= self.gamma * grad_u_f\n",
    "                    self.V[i][f] -= self.gamma * grad_i_f\n",
    "                    self.V[j][f] -= self.gamma * grad_j_f\n",
    "                \n",
    "                # 更新偏置项\n",
    "                grad_bi = loss_uij + self.beta_v * self.bias_V[i]\n",
    "                grad_bj = -loss_uij + self.beta_v * self.bias_V[j]\n",
    "                self.bias_V[i] -= self.gamma * grad_bi\n",
    "                self.bias_V[j] -= self.gamma * grad_bj\n",
    "            \n",
    "            if (iteration + 1) % 100 == 0:\n",
    "                print(f\"完成迭代 {iteration + 1}/{self.iterations}\")\n",
    "\n",
    "    def predict(self, user, item):\n",
    "        \"\"\"预测用户对物品的评分\"\"\"\n",
    "        pred = self.bias_V[item]\n",
    "        for f in range(self.factors):\n",
    "            pred += self.U[user][f] * self.V[item][f]\n",
    "        return pred\n",
    "\n",
    "    def evaluate(self, train_data, test_data, initial_train_data, k=5):\n",
    "        \"\"\"评估模型性能\"\"\"\n",
    "        precision_sum = 0.0\n",
    "        recall_sum = 0.0\n",
    "        eval_users = 0\n",
    "        \n",
    "        for u in range(1, self.user_count + 1):\n",
    "            # 检查用户是否在初始训练集和测试集中\n",
    "            if u not in initial_train_data or u not in test_data:\n",
    "                continue\n",
    "            \n",
    "            # 预测所有物品的评分\n",
    "            predictions = {}\n",
    "            for i in range(1, self.item_count + 1):\n",
    "                # 检查物品是否在初始物品集中且不在用户的初始训练集中\n",
    "                if i in self.initial_item_set and i not in initial_train_data[u]:\n",
    "                    predictions[i] = self.predict(u, i)\n",
    "            \n",
    "            # 获取TopK推荐\n",
    "            rec_items = sorted(predictions.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "            rec_items = {item for item, _ in rec_items}\n",
    "            \n",
    "            # 计算评估指标\n",
    "            eval_users += 1\n",
    "            hits = len(rec_items & test_data[u])\n",
    "            precision_u = hits / k\n",
    "            recall_u = hits / len(test_data[u])\n",
    "            \n",
    "            precision_sum += precision_u\n",
    "            recall_sum += recall_u\n",
    "        \n",
    "        # 计算平均值\n",
    "        precision = precision_sum / eval_users\n",
    "        recall = recall_sum / eval_users\n",
    "        return precision, recall\n",
    "\n",
    "def main():\n",
    "    # 数据路径\n",
    "    train_file = r\"E:\\datasets\\ml-100k\\u1.base\"\n",
    "    test_file = r\"E:\\datasets\\ml-100k\\u1.test\"\n",
    "    \n",
    "    # 初始化模型\n",
    "    bpr = BPR(user_count=943, item_count=1682)\n",
    "    \n",
    "    # 加载数据\n",
    "    train_users, train_items, initial_train_data = bpr.load_data(train_file)\n",
    "    test_users, test_items, _ = bpr.load_data(test_file)\n",
    "    \n",
    "    # 构建训练集和测试集\n",
    "    train_data = defaultdict(set)\n",
    "    for u, i in zip(train_users, train_items):\n",
    "        train_data[u].add(i)\n",
    "        \n",
    "    test_data = defaultdict(set)\n",
    "    for u, i in zip(test_users, test_items):\n",
    "        test_data[u].add(i)\n",
    "    \n",
    "    # 训练模型\n",
    "    bpr.train(train_data)\n",
    "    \n",
    "    # 评估模型\n",
    "    precision, recall = bpr.evaluate(train_data, test_data, initial_train_data, k=5)\n",
    "    print(f\"Precision@5: {precision:.4f}\")\n",
    "    print(f\"Recall@5: {recall:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n",
      "完成迭代 100/100\n",
      "Precision@5: 0.3741\n",
      "Recall@5: 0.1194\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "\n",
    "class BPR:\n",
    "    def __init__(self, user_count=943, item_count=1682):\n",
    "        \"\"\"初始化BPR模型参数\"\"\"\n",
    "        self.user_count = user_count\n",
    "        self.item_count = item_count\n",
    "        self.factors = 20          # 隐因子维度\n",
    "        self.gamma = 0.01         # 学习率\n",
    "        self.alpha_u = 0.01      # 用户正则化系数\n",
    "        self.alpha_v = 0.01      # 物品正则化系数\n",
    "        self.beta_v = 0.01       # 偏置正则化系数\n",
    "        self.iterations = 100     # 迭代次数\n",
    "        \n",
    "        # 初始化模型参数矩阵\n",
    "        self.U = np.random.uniform(-0.01, 0.01, (user_count + 1, self.factors))\n",
    "        self.V = np.random.uniform(-0.01, 0.01, (item_count + 1, self.factors))\n",
    "        self.bias_V = np.zeros(item_count + 1)\n",
    "        \n",
    "        # 数据统计\n",
    "        self.item_set_whole = set()  # 所有评分>=4的物品集合\n",
    "        self.num_train = 0           # 训练样本数\n",
    "        self.item_ratings = defaultdict(int)  # 物品评分计数\n",
    "\n",
    "    def load_data(self, filename):\n",
    "        \"\"\"加载数据，保留评分>=4的记录\"\"\"\n",
    "        user_list = []\n",
    "        item_list = []\n",
    "        \n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                u, i, r = map(float, line.strip().split('\\t')[:3])\n",
    "                u, i = int(u), int(i)\n",
    "                \n",
    "                if r >= 4.0:  # 只保留评分>=4的记录\n",
    "                    user_list.append(u)\n",
    "                    item_list.append(i)\n",
    "                    self.item_set_whole.add(i)\n",
    "                    self.item_ratings[i] += 1\n",
    "                    self.num_train += 1\n",
    "        \n",
    "        # 计算物品偏置\n",
    "        total_ratings = sum(self.item_ratings.values())\n",
    "        avg_ratings = total_ratings / (self.user_count * self.item_count)\n",
    "        \n",
    "        for i in range(1, self.item_count + 1):\n",
    "            if i in self.item_ratings:\n",
    "                self.bias_V[i] = self.item_ratings[i] / self.user_count - avg_ratings\n",
    "        \n",
    "        return user_list, item_list\n",
    "\n",
    "    def train(self, train_data):\n",
    "        \"\"\"训练BPR模型\"\"\"\n",
    "        print(\"开始训练...\")\n",
    "        user_list = list(train_data.keys())\n",
    "        \n",
    "        for iteration in range(self.iterations):\n",
    "            for _ in range(self.num_train):\n",
    "                # 随机采样正样本\n",
    "                u = random.choice(user_list)\n",
    "                if not train_data[u]:\n",
    "                    continue\n",
    "                    \n",
    "                i = random.choice(list(train_data[u]))\n",
    "                \n",
    "                # 采样负样本\n",
    "                while True:\n",
    "                    j = random.randint(1, self.item_count)\n",
    "                    if j in self.item_set_whole and j not in train_data[u]:\n",
    "                        break\n",
    "                \n",
    "                # 计算预测差值\n",
    "                r_ui = np.dot(self.U[u], self.V[i].T) + self.bias_V[i]\n",
    "                r_uj = np.dot(self.U[u], self.V[j].T) + self.bias_V[j]\n",
    "                r_uij = r_ui - r_uj\n",
    "                \n",
    "                # 计算梯度\n",
    "                exp_r_uij = np.exp(r_uij)\n",
    "                sigmoid = 1.0 / (1.0 + exp_r_uij)\n",
    "                \n",
    "                # 更新用户向量\n",
    "                grad_u = sigmoid * (self.V[i] - self.V[j]) - self.alpha_u * self.U[u]\n",
    "                self.U[u] += self.gamma * grad_u\n",
    "                \n",
    "                # 更新物品向量\n",
    "                grad_i = sigmoid * self.U[u] - self.alpha_v * self.V[i]\n",
    "                grad_j = -sigmoid * self.U[u] - self.alpha_v * self.V[j]\n",
    "                self.V[i] += self.gamma * grad_i\n",
    "                self.V[j] += self.gamma * grad_j\n",
    "                \n",
    "                # 更新偏置项\n",
    "                grad_bi = sigmoid - self.beta_v * self.bias_V[i]\n",
    "                grad_bj = -sigmoid - self.beta_v * self.bias_V[j]\n",
    "                self.bias_V[i] += self.gamma * grad_bi\n",
    "                self.bias_V[j] += self.gamma * grad_bj\n",
    "            \n",
    "            if (iteration + 1) % 100 == 0:\n",
    "                print(f\"完成迭代 {iteration + 1}/{self.iterations}\")\n",
    "\n",
    "    def predict(self, u, items):\n",
    "        \"\"\"预测用户对物品集合的评分\"\"\"\n",
    "        return np.dot(self.U[u], self.V[items].T) + self.bias_V[items]\n",
    "\n",
    "    def evaluate(self, train_data, test_data, k=5):\n",
    "        \"\"\"评估模型性能\"\"\"\n",
    "        precision_sum = 0.0\n",
    "        recall_sum = 0.0\n",
    "        eval_users = 0\n",
    "        \n",
    "        for u in test_data:\n",
    "            if u not in train_data:\n",
    "                continue\n",
    "                \n",
    "            # 生成推荐列表\n",
    "            candidates = list(self.item_set_whole - train_data[u])\n",
    "            predictions = self.predict(u, candidates)\n",
    "            rec_items = np.array(candidates)[np.argsort(-predictions)[:k]]\n",
    "            \n",
    "            # 计算评估指标\n",
    "            eval_users += 1\n",
    "            hits = len(set(rec_items) & test_data[u])\n",
    "            \n",
    "            precision_u = hits / k\n",
    "            recall_u = hits / len(test_data[u])\n",
    "            \n",
    "            precision_sum += precision_u\n",
    "            recall_sum += recall_u\n",
    "        \n",
    "        precision = precision_sum / eval_users\n",
    "        recall = recall_sum / eval_users\n",
    "        return precision, recall\n",
    "\n",
    "def main():\n",
    "    # 数据路径\n",
    "    train_file = r\"E:\\datasets\\ml-100k\\u1.base\"\n",
    "    test_file = r\"E:\\datasets\\ml-100k\\u1.test\"\n",
    "    \n",
    "    # 初始化模型\n",
    "    bpr = BPR(user_count=943, item_count=1682)\n",
    "    \n",
    "    # 加载数据\n",
    "    train_users, train_items = bpr.load_data(train_file)\n",
    "    test_users, test_items = bpr.load_data(test_file)\n",
    "    \n",
    "    # 构建用户-物品交互字典\n",
    "    train_data = defaultdict(set)\n",
    "    for u, i in zip(train_users, train_items):\n",
    "        train_data[u].add(i)\n",
    "        \n",
    "    test_data = defaultdict(set)\n",
    "    for u, i in zip(test_users, test_items):\n",
    "        test_data[u].add(i)\n",
    "    \n",
    "    # 训练模型\n",
    "    bpr.train(train_data)\n",
    "    \n",
    "    # 评估模型\n",
    "    precision, recall = bpr.evaluate(train_data, test_data, k=5)\n",
    "    print(f\"Precision@5: {precision:.4f}\")\n",
    "    print(f\"Recall@5: {recall:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"scores.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/17qoo1U4Iw58GRDDIyCaB2GmbRUg1gTPd\n",
    "\"\"\"\n",
    "\n",
    "import heapq\n",
    "import numpy as np\n",
    "import math\n",
    "#计算项目top_K分数\n",
    "def topK_scores(test, predict, topk, user_count, item_count):\n",
    "\n",
    "    PrecisionSum = np.zeros(topk+1)\n",
    "    RecallSum = np.zeros(topk+1)\n",
    "    F1Sum = np.zeros(topk+1)\n",
    "    NDCGSum = np.zeros(topk+1)\n",
    "    OneCallSum = np.zeros(topk+1)\n",
    "    DCGbest = np.zeros(topk+1)\n",
    "    MRRSum = 0\n",
    "    MAPSum = 0\n",
    "    total_test_data_count = 0\n",
    "    for k in range(1, topk+1):\n",
    "        DCGbest[k] = DCGbest[k - 1]\n",
    "        DCGbest[k] += 1.0 / math.log(k + 1)\n",
    "    for i in range(user_count):\n",
    "        user_test = []\n",
    "        user_predict = []\n",
    "        test_data_size = 0\n",
    "        for j in range(item_count):\n",
    "            if test[i * item_count + j] == 1.0:\n",
    "                test_data_size += 1\n",
    "            user_test.append(test[i * item_count + j])\n",
    "            user_predict.append(predict[i * item_count + j])\n",
    "        if test_data_size == 0:\n",
    "            continue\n",
    "        else:\n",
    "            total_test_data_count += 1\n",
    "        predict_max_num_index_list = map(user_predict.index, heapq.nlargest(topk, user_predict))\n",
    "        predict_max_num_index_list = list(predict_max_num_index_list)\n",
    "        hit_sum = 0\n",
    "        DCG = np.zeros(topk + 1)\n",
    "        DCGbest2 = np.zeros(topk + 1)\n",
    "        for k in range(1, topk + 1):\n",
    "            DCG[k] = DCG[k - 1]\n",
    "            item_id = predict_max_num_index_list[k - 1]\n",
    "            if user_test[item_id] == 1:\n",
    "                hit_sum += 1\n",
    "                DCG[k] += 1 / math.log(k + 1)\n",
    "            # precision, recall, F1, 1-call\n",
    "            prec = float(hit_sum / k)\n",
    "            rec = float(hit_sum / test_data_size)\n",
    "            f1 = 0.0\n",
    "            if prec + rec > 0:\n",
    "                f1 = 2 * prec * rec / (prec + rec)\n",
    "            PrecisionSum[k] += float(prec)\n",
    "            RecallSum[k] += float(rec)\n",
    "            F1Sum[k] += float(f1)\n",
    "            if test_data_size >= k:\n",
    "                DCGbest2[k] = DCGbest[k]\n",
    "            else:\n",
    "                DCGbest2[k] = DCGbest2[k-1]\n",
    "            NDCGSum[k] += DCG[k] / DCGbest2[k]\n",
    "            if hit_sum > 0:\n",
    "                OneCallSum[k] += 1\n",
    "            else:\n",
    "                OneCallSum[k] += 0\n",
    "        # MRR\n",
    "        p = 1\n",
    "        for mrr_iter in predict_max_num_index_list:\n",
    "            if user_test[mrr_iter] == 1:\n",
    "                break\n",
    "            p += 1\n",
    "        MRRSum += 1 / float(p)\n",
    "        # MAP\n",
    "        p = 1\n",
    "        AP = 0.0\n",
    "        hit_before = 0\n",
    "        for mrr_iter in predict_max_num_index_list:\n",
    "            if user_test[mrr_iter] == 1:\n",
    "                AP += 1 / float(p) * (hit_before + 1)\n",
    "                hit_before += 1\n",
    "            p += 1\n",
    "        MAPSum += AP / test_data_size\n",
    "    print('MAP:', MAPSum / total_test_data_count)\n",
    "    print('MRR:', MRRSum / total_test_data_count)\n",
    "    print('Prec@5:', PrecisionSum[4] / total_test_data_count)\n",
    "    print('Rec@5:', RecallSum[4] / total_test_data_count)\n",
    "    print('F1@5:', F1Sum[4] / total_test_data_count)\n",
    "    print('NDCG@5:', NDCGSum[4] / total_test_data_count)\n",
    "    print('1-call@5:', OneCallSum[4] / total_test_data_count)\n",
    "    return\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
