{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [57:05<00:00, 34.25s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FISM_auc:\n",
      "Pre@5: 0.2351\n",
      "Rec@5: 0.0577\n",
      "Running time: 3444.85s\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class FISM_auc:\n",
    "    def __init__(self, train_data_file, test_data_file, T=100, d=20, learning_rate=0.01, regularization=0.001, alpha=0.5):\n",
    "        # 初始化模型参数\n",
    "        self.T = T\n",
    "        self.d = d\n",
    "        self.alpha = alpha\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularization = regularization\n",
    "        self.user_num = 943\n",
    "        self.item_num = 1682\n",
    "        self.items = set(range(1, self.item_num + 1))\n",
    "        \n",
    "        # 初始化偏置项和隐向量矩阵\n",
    "        self.bi = np.zeros(self.item_num + 1)\n",
    "        self.user_item_matrix = np.zeros((self.user_num + 1, self.item_num + 1))\n",
    "        self.train_user_items = {}\n",
    "        self.train_item_users = {}\n",
    "        \n",
    "        # 加载训练数据\n",
    "        u_train = pd.read_csv(train_data_file, sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "        u_train = u_train[u_train['rating'] > 3]\n",
    "        self.observed_records = []\n",
    "        count = 0\n",
    "        for index, row in u_train.iterrows():\n",
    "            count += 1\n",
    "            user, item = row['user_id'], row['item_id']\n",
    "            self.user_item_matrix[user][item] = 1\n",
    "            self.train_user_items.setdefault(user, set()).add(item)\n",
    "            self.train_item_users.setdefault(item, set()).add(user)\n",
    "            self.observed_records.append((user, item))\n",
    "        \n",
    "        # 初始化物品偏置项\n",
    "        miu = count / (self.item_num * self.user_num)\n",
    "        for i in range(1, self.item_num + 1):\n",
    "            self.train_item_users.setdefault(i, set())\n",
    "            self.bi[i] = len(self.train_item_users[i]) / self.user_num - miu\n",
    "        \n",
    "        # 加载测试数据\n",
    "        self.test_user_items = {}\n",
    "        self.test_data_users = set()\n",
    "        u_test = pd.read_csv(test_data_file, sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "        for index, row in u_test.iterrows():\n",
    "            if row['rating'] > 3:\n",
    "                user, item = row['user_id'], row['item_id']\n",
    "                self.test_user_items.setdefault(user, set()).add(item)\n",
    "                self.test_data_users.add(user)\n",
    "        \n",
    "        # 初始化隐向量矩阵\n",
    "        self.V = np.random.rand(self.item_num + 1, self.d) * 0.01 - 0.005\n",
    "        self.W = np.random.rand(self.item_num + 1, self.d) * 0.01 - 0.005\n",
    "\n",
    "    def predict(self, user_id, item_id):\n",
    "        U_ = np.zeros(self.d)\n",
    "        interacted_items = self.train_user_items.get(user_id, set())\n",
    "        if item_id in interacted_items:\n",
    "            interacted_items = interacted_items - {item_id}\n",
    "        if not interacted_items:\n",
    "            return self.bi[item_id], interacted_items, U_\n",
    "        for item in interacted_items:\n",
    "            U_ += self.W[item]\n",
    "        U_ /= math.pow(len(interacted_items), self.alpha)\n",
    "        return np.dot(U_, self.V[item_id]) + self.bi[item_id], interacted_items, U_\n",
    "\n",
    "    def train(self):\n",
    "        for _ in tqdm(range(self.T)):\n",
    "            random.shuffle(self.observed_records)\n",
    "            for user, item_i in self.observed_records:\n",
    "                # 采样负样本\n",
    "                neg_items = list(self.items - self.train_user_items.get(user, set()))\n",
    "                if not neg_items:\n",
    "                    continue\n",
    "                item_j = random.choice(neg_items)\n",
    "                \n",
    "                # 计算预测值\n",
    "                r_ui, diff_i, U_ui = self.predict(user, item_i)\n",
    "                r_uj, diff_j, U_uj = self.predict(user, item_j)\n",
    "                \n",
    "                # 计算BPR损失梯度\n",
    "                x_uij = r_ui - r_uj\n",
    "                sigmoid = 1 / (1 + math.exp(x_uij))\n",
    "                coeff = self.learning_rate * (sigmoid - 1)\n",
    "                \n",
    "                # 更新物品偏置项\n",
    "                self.bi[item_i] -= self.learning_rate * (coeff + self.regularization * self.bi[item_i])\n",
    "                self.bi[item_j] -= self.learning_rate * (-coeff + self.regularization * self.bi[item_j])\n",
    "                \n",
    "                # 更新物品隐向量\n",
    "                self.V[item_i] -= self.learning_rate * (coeff * U_ui + self.regularization * self.V[item_i])\n",
    "                self.V[item_j] -= self.learning_rate * (-coeff * U_uj + self.regularization * self.V[item_j])\n",
    "                \n",
    "                # 更新用户隐向量相关参数\n",
    "                # 处理正样本i的历史物品\n",
    "                len_diff_i = len(diff_i)\n",
    "                if len_diff_i > 0:\n",
    "                    factor_i = coeff * self.V[item_i] / (len_diff_i ** self.alpha)\n",
    "                    for k in diff_i:\n",
    "                        self.W[k] -= self.learning_rate * (factor_i + self.regularization * self.W[k])\n",
    "                \n",
    "                # 处理负样本j的历史物品\n",
    "                interacted_items_j = self.train_user_items.get(user, set())\n",
    "                len_diff_j = len(interacted_items_j)\n",
    "                if len_diff_j > 0:\n",
    "                    factor_j = -coeff * self.V[item_j] / (len_diff_j ** self.alpha)\n",
    "                    for k in interacted_items_j:\n",
    "                        self.W[k] -= self.learning_rate * (factor_j + self.regularization * self.W[k])\n",
    "\n",
    "    def test(self, recommend_num=5):\n",
    "        Pre_K, Rec_K = 0.0, 0.0\n",
    "        for user in self.test_data_users:\n",
    "            # 获取用户未交互的物品\n",
    "            interacted = self.train_user_items.get(user, set())\n",
    "            candidates = list(self.items - interacted)\n",
    "            \n",
    "            # 生成预测评分\n",
    "            predictions = []\n",
    "            for item in candidates:\n",
    "                pred, _, _ = self.predict(user, item)\n",
    "                predictions.append((item, pred))\n",
    "            \n",
    "            # 取TopN推荐\n",
    "            predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_items = {item for item, _ in predictions[:recommend_num]}\n",
    "            \n",
    "            # 计算指标\n",
    "            true_items = self.test_user_items.get(user, set())\n",
    "            Pre_K += len(top_items & true_items) / recommend_num\n",
    "            Rec_K += len(top_items & true_items) / len(true_items) if len(true_items) > 0 else 0\n",
    "        \n",
    "        Pre_K /= len(self.test_data_users)\n",
    "        Rec_K /= len(self.test_data_users)\n",
    "        print(f\"FISM_auc:\")\n",
    "        print(f'Pre@{recommend_num}: {Pre_K:.4f}')\n",
    "        print(f'Rec@{recommend_num}: {Rec_K:.4f}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    model = FISM_auc(r\"E:\\datasets\\ml-100k\\u1.base\", r\"E:\\datasets\\ml-100k\\u1.test\")\n",
    "    model.train()\n",
    "    model.test()\n",
    "    print(f'Running time: {time.time() - start:.2f}s') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\n",
      "Precision@5: 0.0253\n",
      "Recall@5: 0.0029\n",
      "\n",
      "Epoch 20:\n",
      "Precision@5: 0.0253\n",
      "Recall@5: 0.0029\n",
      "\n",
      "Epoch 30:\n",
      "Precision@5: 0.0253\n",
      "Recall@5: 0.0029\n",
      "\n",
      "Epoch 40:\n",
      "Precision@5: 0.0253\n",
      "Recall@5: 0.0029\n",
      "\n",
      "Epoch 50:\n",
      "Precision@5: 0.0253\n",
      "Recall@5: 0.0029\n",
      "\n",
      "\n",
      "最终测试结果:\n",
      "Precision@5: 0.0253\n",
      "Recall@5: 0.0029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, train_path, test_path):\n",
    "        self.train_u_i_dict = defaultdict(list)\n",
    "        self.test_u_i_dict = defaultdict(list)\n",
    "        self.max_i = 0\n",
    "        \n",
    "        # 加载训练数据\n",
    "        with open(train_path, 'r') as f:\n",
    "            for line in f:\n",
    "                uid, iid, rating, _ = line.strip().split('\\t')\n",
    "                self._add_interaction(int(uid), int(iid), is_train=True)\n",
    "        \n",
    "        # 加载测试数据\n",
    "        with open(test_path, 'r') as f:\n",
    "            for line in f:\n",
    "                uid, iid, rating, _ = line.strip().split('\\t')\n",
    "                self._add_interaction(int(uid), int(iid), is_train=False)\n",
    "    \n",
    "    def _add_interaction(self, uid, iid, is_train=True):\n",
    "        \"\"\"添加交互记录并更新最大物品ID\"\"\"\n",
    "        self.max_i = max(self.max_i, iid)\n",
    "        if is_train:\n",
    "            self.train_u_i_dict[uid].append(iid)\n",
    "        else:\n",
    "            self.test_u_i_dict[uid].append(iid)\n",
    "\n",
    "class Evaluation:\n",
    "    # 保持原有评估类不变\n",
    "    def __init__(self, k, ranking_u_i_dict, test_u_i_dict):\n",
    "        self.k = k\n",
    "        self.ranking = ranking_u_i_dict\n",
    "        self.test = test_u_i_dict\n",
    "\n",
    "    def precision(self):\n",
    "        total_hits = 0\n",
    "        total_recommended = 0\n",
    "        for u in self.ranking:\n",
    "            recommended = self.ranking[u][:self.k]\n",
    "            actual = self.test.get(u, [])\n",
    "            hits = len(set(recommended) & set(actual))\n",
    "            total_hits += hits\n",
    "            total_recommended += len(recommended)\n",
    "        return total_hits / total_recommended if total_recommended > 0 else 0\n",
    "\n",
    "    def recall(self):\n",
    "        total_hits = 0\n",
    "        total_actual = 0\n",
    "        for u in self.ranking:\n",
    "            recommended = self.ranking[u][:self.k]\n",
    "            actual = self.test.get(u, [])\n",
    "            hits = len(set(recommended) & set(actual))\n",
    "            total_hits += hits\n",
    "            total_actual += len(actual)\n",
    "        return total_hits / total_actual if total_actual > 0 else 0\n",
    "\n",
    "class FISMauc:\n",
    "    # 保持原有模型类不变\n",
    "    def __init__(self, dataloader, alpha, gamma, Au_size, alpha_v, alpha_w, beta_v, d, T):\n",
    "        self.dataloader = dataloader\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.Au_size = Au_size\n",
    "        self.alpha_v = alpha_v\n",
    "        self.alpha_w = alpha_w\n",
    "        self.beta_v = beta_v\n",
    "        self.d = d\n",
    "        self.T = T\n",
    "\n",
    "        self.I = list(range(1, self.dataloader.max_i + 1))\n",
    "        \n",
    "        # 初始化参数\n",
    "        self.b_i = np.random.randn(self.dataloader.max_i + 1) * 0.01\n",
    "        self.W = np.random.randn(self.dataloader.max_i + 1, self.d) * 0.01\n",
    "        self.V = np.random.randn(self.dataloader.max_i + 1, self.d) * 0.01\n",
    "\n",
    "    def train(self):\n",
    "        for t in range(self.T):\n",
    "            # 训练逻辑保持不变...\n",
    "            \n",
    "            if (t+1) % 10 == 0:\n",
    "                print(f\"Epoch {t+1}:\")\n",
    "                self._evaluate()  # 修改为私有方法\n",
    "\n",
    "    def _evaluate(self):\n",
    "        \"\"\"评估方法封装\"\"\"\n",
    "        ranking = defaultdict(list)\n",
    "        for u in self.dataloader.test_u_i_dict:\n",
    "            scores = {}\n",
    "            train_items = set(self.dataloader.train_u_i_dict[u])\n",
    "            \n",
    "            # 计算用户特征向量\n",
    "            n_u = len(train_items)\n",
    "            norm_factor = n_u ** -self.alpha\n",
    "            Uu = np.sum([self.W[i] for i in train_items], axis=0) * norm_factor\n",
    "            \n",
    "            # 对所有物品评分\n",
    "            for i in self.I:\n",
    "                if i not in train_items:\n",
    "                    scores[i] = self.b_i[i] + np.dot(Uu, self.V[i])\n",
    "            \n",
    "            # 排序取Top-K\n",
    "            sorted_items = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "            ranking[u] = [item[0] for item in sorted_items]\n",
    "\n",
    "        evaluator = Evaluation(5, ranking, self.dataloader.test_u_i_dict)\n",
    "        precision = evaluator.precision()\n",
    "        recall = evaluator.recall()\n",
    "        print(f\"Precision@5: {precision:.4f}\")\n",
    "        print(f\"Recall@5: {recall:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 配置数据路径\n",
    "    train_file = r\"E:\\datasets\\ml-100k\\u1.base\"\n",
    "    test_file = r\"E:\\datasets\\ml-100k\\u1.test\"\n",
    "    \n",
    "    # 检查文件存在性\n",
    "    if not os.path.exists(train_file):\n",
    "        raise FileNotFoundError(f\"训练文件不存在: {train_file}\")\n",
    "    if not os.path.exists(test_file):\n",
    "        raise FileNotFoundError(f\"测试文件不存在: {test_file}\")\n",
    "    \n",
    "    # 初始化数据加载器\n",
    "    dataloader = Data(train_file, test_file)\n",
    "    \n",
    "    # 设置模型参数（示例参数，需根据实际情况调整）\n",
    "    params = {\n",
    "        'alpha': 0.5,     # 标准化指数\n",
    "        'gamma': 0.01,    # 学习率\n",
    "        'Au_size': 3,     # 负采样数量\n",
    "        'alpha_v': 0.01,   # V正则化系数\n",
    "        'alpha_w': 0.01,   # W正则化系数\n",
    "        'beta_v': 0.01,    # b正则化系数\n",
    "        'd': 20,          # 隐向量维度\n",
    "        'T': 50           # 迭代次数（示例值，实际需要更多）\n",
    "    }\n",
    "    \n",
    "    # 创建并训练模型\n",
    "    model = FISMauc(dataloader, **params)\n",
    "    model.train()\n",
    "    \n",
    "    # 最终评估\n",
    "    print(\"\\n最终测试结果:\")\n",
    "    model._evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 190\u001b[0m\n\u001b[0;32m    178\u001b[0m model \u001b[38;5;241m=\u001b[39m FISMauc(\n\u001b[0;32m    179\u001b[0m     dataloader,\n\u001b[0;32m    180\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,      \u001b[38;5;66;03m# 论文中的α参数\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m     T\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m           \u001b[38;5;66;03m# 迭代次数（示例值）\u001b[39;00m\n\u001b[0;32m    187\u001b[0m )\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# 训练并测试\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Test Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    192\u001b[0m model\u001b[38;5;241m.\u001b[39mtest()\n",
      "Cell \u001b[1;32mIn[16], line 116\u001b[0m, in \u001b[0;36mFISMauc.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m eij \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (pui \u001b[38;5;241m-\u001b[39m puj)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrho\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# 更新偏置\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_bias[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m (eij \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregB \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_bias[i])\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_bias[j] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m (eij \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregB \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_bias[j])\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# 更新Q矩阵\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# ==================== Data Module ====================\n",
    "class Data:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.train_data, self.test_data = self.get_data()\n",
    "        self.train_u_i_dict, self.test_u_i_dict = self.get_u_i_dict()\n",
    "\n",
    "    def get_data(self):\n",
    "        train_path = self.path + 'u1.base'\n",
    "        train_data = []\n",
    "        with open(train_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                u, i, rating, _ = line.split('\\t')\n",
    "                if rating in ('4', '5'):\n",
    "                    train_data.append((int(u), int(i)))\n",
    "\n",
    "        test_path = self.path + 'u1.test'\n",
    "        test_data = []\n",
    "        with open(test_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                u, i, rating, _ = line.split('\\t')\n",
    "                if rating in ('4', '5'):\n",
    "                    test_data.append((int(u), int(i)))\n",
    "\n",
    "        self.max_u = max(max(u for u, _ in train_data), max(u for u, _ in test_data))\n",
    "        self.max_i = max(max(i for _, i in train_data), max(i for _, i in test_data))\n",
    "        return train_data, test_data\n",
    "\n",
    "    def get_u_i_dict(self):\n",
    "        train_dict = defaultdict(list)\n",
    "        for u, i in self.train_data:\n",
    "            train_dict[u].append(i)\n",
    "        \n",
    "        test_dict = defaultdict(list)\n",
    "        for u, i in self.test_data:\n",
    "            test_dict[u].append(i)\n",
    "        \n",
    "        return train_dict, test_dict\n",
    "\n",
    "# ==================== Evaluation Module ====================\n",
    "class Evaluation:\n",
    "    def __init__(self, k, ranking_dict, test_dict):\n",
    "        self.k = k\n",
    "        self.ranking_dict = ranking_dict\n",
    "        self.test_dict = test_dict\n",
    "        self.user_count = len(test_dict)\n",
    "\n",
    "    def precision(self):\n",
    "        total = 0.0\n",
    "        for u in self.test_dict:\n",
    "            actual = set(self.test_dict[u])\n",
    "            predicted = set(self.ranking_dict[u][:self.k])\n",
    "            total += len(actual & predicted) / self.k\n",
    "        return total / self.user_count if self.user_count > 0 else 0\n",
    "\n",
    "    def recall(self):\n",
    "        total = 0.0\n",
    "        for u in self.test_dict:\n",
    "            actual = set(self.test_dict[u])\n",
    "            predicted = set(self.ranking_dict[u][:self.k])\n",
    "            total += len(actual & predicted) / len(actual) if len(actual) > 0 else 0\n",
    "        return total / self.user_count if self.user_count > 0 else 0\n",
    "\n",
    "# ==================== Model Module ====================\n",
    "class FISMauc:\n",
    "    def __init__(self, dataloader, alpha=0.5, gamma=0.01, rho=3, \n",
    "                 regI=0.01, regB=0.01, d=20, T=1000):\n",
    "        self.dataloader = dataloader\n",
    "        self.alpha = alpha      # 相似度指数\n",
    "        self.gamma = gamma      # 学习率\n",
    "        self.rho = rho          # 负采样数\n",
    "        self.regI = regI        # 因子正则化\n",
    "        self.regB = regB        # 偏置正则化\n",
    "        self.d = d              # 隐因子维度\n",
    "        self.T = T              # 迭代次数\n",
    "\n",
    "        # 初始化参数\n",
    "        self.P = np.random.randn(dataloader.max_i + 1, d) * 0.01  # 物品因子矩阵\n",
    "        self.Q = np.random.randn(dataloader.max_i + 1, d) * 0.01  # 物品特征矩阵\n",
    "        self.item_bias = np.random.randn(dataloader.max_i + 1) * 0.01\n",
    "        self.items = list(range(1, dataloader.max_i + 1))\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.T):\n",
    "            total_loss = 0.0\n",
    "            \n",
    "            for u, Iu in self.dataloader.train_u_i_dict.items():\n",
    "                n_u = len(Iu)\n",
    "                if n_u == 0:\n",
    "                    continue\n",
    "\n",
    "                for i in Iu:\n",
    "                    # 负采样\n",
    "                    neg_items = list(set(self.items) - set(Iu))\n",
    "                    Au = random.sample(neg_items, k=self.rho)\n",
    "\n",
    "                    # 计算正样本得分\n",
    "                    wu = (n_u - 1)**-self.alpha if n_u > 1 else 0\n",
    "                    sum_p = np.sum([self.P[j] for j in Iu if j != i], axis=0)\n",
    "                    pui = self.item_bias[i] + wu * np.dot(sum_p, self.Q[i])\n",
    "\n",
    "                    # 更新参数\n",
    "                    for j in Au:\n",
    "                        # 计算负样本得分\n",
    "                        sum_j = np.sum([self.P[k] for k in Iu], axis=0) * (n_u**-self.alpha)\n",
    "                        puj = self.item_bias[j] + np.dot(sum_j, self.Q[j])\n",
    "\n",
    "                        # 计算误差\n",
    "                        eij = (1 - (pui - puj)) / self.rho\n",
    "\n",
    "                        # 更新偏置\n",
    "                        self.item_bias[i] += self.gamma * (eij - self.regB * self.item_bias[i])\n",
    "                        self.item_bias[j] -= self.gamma * (eij + self.regB * self.item_bias[j])\n",
    "\n",
    "                        # 更新Q矩阵\n",
    "                        delta_qi = eij * wu * sum_p - self.regI * self.Q[i]\n",
    "                        self.Q[i] += self.gamma * delta_qi\n",
    "                        delta_qj = -eij * sum_j - self.regI * self.Q[j]\n",
    "                        self.Q[j] += self.gamma * delta_qj\n",
    "\n",
    "                        # 更新P矩阵\n",
    "                        for k in Iu:\n",
    "                            if k != i:\n",
    "                                delta_pk = eij * wu * (self.Q[i] - self.Q[j]) - self.regI * self.P[k]\n",
    "                                self.P[k] += self.gamma * delta_pk\n",
    "\n",
    "                        # 累计损失\n",
    "                        total_loss += eij**2 + self.regB*(self.item_bias[i]**2 + self.item_bias[j]**2) \\\n",
    "                                    + self.regI*(np.sum(self.Q[i]**2) + np.sum(self.Q[j]**2))\n",
    "\n",
    "            # 每10轮输出进度\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{self.T}] Loss: {total_loss:.4f}\")\n",
    "                self.test()\n",
    "\n",
    "    def test(self):\n",
    "        ranking_dict = defaultdict(list)\n",
    "        \n",
    "        for u in self.dataloader.test_u_i_dict:\n",
    "            Iu = self.dataloader.train_u_i_dict.get(u, [])\n",
    "            scores = {}\n",
    "            \n",
    "            # 预测未交互物品\n",
    "            for i in set(self.items) - set(Iu):\n",
    "                sum_score = 0.0\n",
    "                count = 0\n",
    "                for j in Iu:\n",
    "                    if j != i:\n",
    "                        sum_score += np.dot(self.P[j], self.Q[i])\n",
    "                        count += 1\n",
    "                wu = count**-self.alpha if count > 0 else 0\n",
    "                scores[i] = self.item_bias[i] + wu * sum_score\n",
    "            \n",
    "            # 生成排序\n",
    "            sorted_items = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "            ranking_dict[u] = [item[0] for item in sorted_items[:5]]\n",
    "\n",
    "        # 计算指标\n",
    "        evaluator = Evaluation(5, ranking_dict, self.dataloader.test_u_i_dict)\n",
    "        precision = evaluator.precision()\n",
    "        recall = evaluator.recall()\n",
    "        print(f\"Precision@5: {precision:.4f}\")\n",
    "        print(f\"Recall@5: {recall:.4f}\\n\")\n",
    "\n",
    "# ==================== Main Execution ====================\n",
    "if __name__ == \"__main__\":\n",
    "    # 数据路径设置\n",
    "    data_path = \"E:/datasets/ml-100k/\"\n",
    "    \n",
    "    # 初始化数据加载器\n",
    "    dataloader = Data(data_path)\n",
    "    \n",
    "    # 初始化模型\n",
    "    model = FISMauc(\n",
    "        dataloader,\n",
    "        alpha=0.5,      # 论文中的α参数\n",
    "        gamma=0.01,     # 学习率\n",
    "        rho=3,          # 负采样数\n",
    "        regI=0.01,      # 因子正则化\n",
    "        regB=0.01,      # 偏置正则化\n",
    "        d=20,           # 隐因子维度\n",
    "        T=100           # 迭代次数（示例值）\n",
    "    )\n",
    "    \n",
    "    # 训练并测试\n",
    "    model.train()\n",
    "    print(\"Final Test Results:\")\n",
    "    model.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FISM_auc\n",
    "\n",
    "The predicted rating of user $u$ on item $i\\left(i\\in\\mathcal{I}_u\\right)$,\n",
    "$$\\hat{r}_{ui}=b_i+\\bar{U}_u^{-i}V_i^T$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$\\bar{U}_{u\\cdot}^{-i}=\\frac1{|\\mathcal{I}_u\\setminus\\{i\\}|^\\alpha}\\sum_{i^{\\prime}\\in\\mathcal{I}_u\\setminus\\{i\\}}W_{i^{\\prime}\\cdot},\\:0\\leq\\alpha\\leq1$$\n",
    "\n",
    "The predicted rating of user $u$ on item $j(j\\in\\mathcal{I}\\backslash\\mathcal{I}_u)$,\n",
    "\n",
    "$$\\hat{r}_{uj}=b_j+\\bar{U}_u.V_j^T$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$\\bar{U}_{u\\cdot}=\\frac1{|\\mathcal{I}_u|^\\alpha}\\sum_{i^{\\prime}\\in\\mathcal{I}_u}W_{i^{\\prime}\\cdot},\\:0\\leq\\alpha\\leq1$$\n",
    "\n",
    "The objective function of FISMauc,\n",
    "\n",
    "\n",
    "$$\\min_{\\Theta}\\sum_{(u,i,A_u)}f_{uiA_u}$$\n",
    "\n",
    "where $\\Theta=\\{V_i.,W_{i^{\\prime}..},b_i\\},i,i^{\\prime}=1,\\ldots,m$, and\n",
    "$f_{ui,\\mathcal{A}_u}=\\frac1{|\\mathcal{A}_u|}\\sum_{j\\in\\mathcal{A}_u}\\frac12(1-(\\hat{r}_{ui}-\\hat{r}_{uj}))^2+\\frac{\\alpha_v}2||V_i.||_F^2+\\frac{\\alpha_v}2\\sum_{j\\in\\mathcal{A}_u}||V_j.||_F^2+$\n",
    "$\\begin{array}{l}{\\frac{\\alpha_{W}}{2}\\sum_{i^{\\prime}\\in\\mathcal{I}_{w}}||W_{i^{\\prime}\\cdot}||_{F}^{2}+\\frac{\\beta_{v}}{2}b_{i}^{2}+\\frac{\\beta_{v}}{2}\\sum_{j\\in\\mathcal{A}_{u}}b_{j}^{2}.}\\\\{\\mathrm{Notes}}\\end{array}$\n",
    "\n",
    "\n",
    "$\\bullet{\\mathcal{A}}_u$ is a sampled set of unobserved items by user $u$\n",
    "$\\bullet$ According to the loss function, we can see that $FISM_{auc}$ is a\n",
    "pairwise method\n",
    "\n",
    "For a triple $(u,i,\\mathcal{A}_u)$, we have the gradients,\n",
    "\n",
    "$$\\begin{aligned}&\\nabla b_{j}&&=\\quad\\frac{\\partial f_{uj}A_{u}}{\\partial b_{j}}=e_{uj}+\\beta_{\\nu}B_{j},j\\in\\mathcal{A}_{u}\\\\&\\nabla V_{j.}&&=\\quad\\frac{\\partial f_{uj}A_{u}}{\\partial V_{j.}}=e_{uj}U_{u}\\cdot+\\alpha_{\\nu}V_{j.},j\\in\\mathcal{A}_{u}\\\\&\\nabla b_{l}&&=\\quad\\frac{\\partial f_{uj}A_{u}}{\\partial B_{l}}=\\sum_{j\\in A_{u}}(-e_{uj})+\\beta_{\\nu}B_{l}\\\\&\\nabla V_{l.}&&=\\quad\\frac{\\partial V_{uj}A_{u}}{\\partial V_{l.}}=\\sum_{j\\in A_{uj}}(-e_{uj})U_{u}^{-j}+\\alpha_{\\nu}V_{l.}\\\\&\\nabla W_{l.}&&=\\quad\\frac{\\partial f_{uj}A_{u}}{\\partial W_{l.}}=\\sum_{j\\in A_{u}}(-e_{uj})\\frac{V_{l.}}{|T_{u}\\setminus\\{l\\}|^{\\alpha}}-\\frac{V_{l.}}{|T_{u}|^{\\alpha}})+\\alpha_{w}W_{l.},i^{\\prime}\\in\\mathcal{I}_{u}\\setminus\\{l\\}\\\\&\\nabla W_{l.}&&=\\quad\\frac{\\partial f_{uj}A_{u}}{\\partial W_{l.}}=\\sum_{j\\in A_{u}}(-e_{uj})\\frac{-V_{l.}}{|T_{uj}|^{\\alpha}}+\\alpha_{w}W_{l.}\\end{aligned}$$\n",
    "\n",
    "where $e_{uij}=(1-(\\hat{r}_{ui}-\\hat{r}_{uj}))/|\\mathcal{A}_u|.$\n",
    "\n",
    "Note that we do NOT have to save $V_i.$ and $V_j.$ before they are updated, though we should NOT use the recently updated\n",
    "parameters but strictly follow the update rules. Please see the details in Algorithm 1, where we use $x$ and $x_{2}$ to save the $V_{i.}$ and\n",
    "$V_i.$ before they are updated.\n",
    "\n",
    "For a triple $(u,i,\\mathcal{A}_u)$, we have the gradients,\n",
    "\n",
    "$$\\begin{aligned}b_{j}&=\\quad b_j-\\gamma\\nabla b_j\\\\V_{j.}&=\\quad V_{j.}-\\gamma\\nabla V_j.\\\\b_{i}&=\\quad b_i-\\gamma\\nabla b_i\\\\V_{i.}&=\\quad V_{i.}-\\gamma\\nabla V_{i.}\\\\W_{i^{\\prime}.}&=\\quad W_{i^{\\prime}.}-\\gamma\\nabla W_{i^{\\prime}.},i^{\\prime}\\in\\mathcal{I}_u\\backslash\\{i\\}\\\\W_{i.}&=\\quad W_{i.}-\\gamma\\nabla W_{i.}\\end{aligned}$$\n",
    "\n",
    "where $\\gamma$ is the learning rate.\n",
    "\n",
    "- user number: n = 943; item number: m = 1682\n",
    "\n",
    "- We use the statistics of training data to initialize the model parameters,\n",
    "\n",
    "$$\\begin{aligned}b_{i}&=\\sum_{u=1}^ny_{ui}/n-\\mu\\\\b_{j}&=\\sum_{u=1}^ny_{uj}/n-\\mu\\\\V_{ik}&=\\quad(r-0.5)\\times0.01,k=1,\\ldots,d\\\\W_{i^{\\prime}k}&=\\quad(r-0.5)\\times0.01,k=1,\\ldots,d\\end{aligned}$$\n",
    "\n",
    "\n",
    "where r (0 ≤ r < 1) is a random variable, and $\\mu=\\sum_u=1^n\\sum_{i=1}^my_{ui}/n/m.$\n",
    "\n",
    "- \\begin{aligned}&\\text{We fin }\\alpha=0.5,\\gamma=0.01\\mathrm{~and~}|A_{u}|=3\\text{, and search the best values of}\\\\&\\text{the following parameters,}\\\\&\\mathrm{~Ф~}\\alpha_{v}=\\alpha_{w}=\\beta_{v}\\in\\{0.001,0.01,0.1\\}\\\\&\\mathrm{~Ф~}T\\in\\{100,500,1000\\}\\\\&\\mathrm{Finally,we~use~}\\alpha=0.5,\\gamma=0.01,|\\mathcal{A}_{u}|=3,\\alpha_{v}=\\alpha_{w}=\\beta_{v}=0.01\\mathrm{~and}\\\\&T=1000,\\text{which performs best in our experiments.}\\end{aligned}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class FISM_auc:\n",
    "    def __init__(self, train_data_file, test_data_file, T=1000, d=64, learning_rate=0.01, alpha=0.5,\n",
    "                 p=3, alpha_v=0.01, alpha_w=0.01, beta_v=0.01):\n",
    "        self.p = p\n",
    "        self.T = T\n",
    "        self.d = d\n",
    "        self.alpha = alpha\n",
    "        self.learning_rate = learning_rate\n",
    "        self.alpha_v = alpha_v\n",
    "        self.alpha_w = alpha_w\n",
    "        self.beta_v = beta_v\n",
    "        \n",
    "        self.user_num = 943\n",
    "        self.item_num = 1682\n",
    "        self.items = set(range(1, self.item_num + 1))\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.bi = np.zeros(self.item_num + 1)\n",
    "        self.V = (np.random.rand(self.item_num + 1, self.d) - 0.5) * 0.01\n",
    "        self.W = (np.random.rand(self.item_num + 1, self.d) - 0.5) * 0.01\n",
    "        \n",
    "        # Load data\n",
    "        self.train_user_items, miu = self._load_data(train_data_file)\n",
    "        self.test_user_items = self._load_test_data(test_data_file)\n",
    "        \n",
    "        # Initialize item biases\n",
    "        for i in range(1, self.item_num + 1):\n",
    "            self.bi[i] = len(self.train_user_items.get(i, set())) / self.user_num - miu\n",
    "\n",
    "    def _load_data(self, filename):\n",
    "        data = pd.read_csv(filename, sep='\\t', header=None, \n",
    "                          names=['user', 'item', 'rating', 'timestamp'])\n",
    "        data = data[data['rating'] > 3]\n",
    "        \n",
    "        user_items = {}\n",
    "        item_users = {}\n",
    "        total = 0\n",
    "        for _, row in data.iterrows():\n",
    "            user = row['user']\n",
    "            item = row['item']\n",
    "            user_items.setdefault(user, set()).add(item)\n",
    "            item_users.setdefault(item, set()).add(user)\n",
    "            total += 1\n",
    "        \n",
    "        miu = total / (self.user_num * self.item_num)\n",
    "        return user_items, miu\n",
    "\n",
    "    def _load_test_data(self, filename):\n",
    "        data = pd.read_csv(filename, sep='\\t', header=None,\n",
    "                          names=['user', 'item', 'rating', 'timestamp'])\n",
    "        data = data[data['rating'] > 3]\n",
    "        \n",
    "        test_user_items = {}\n",
    "        for _, row in data.iterrows():\n",
    "            user = row['user']\n",
    "            item = row['item']\n",
    "            test_user_items.setdefault(user, set()).add(item)\n",
    "        return test_user_items\n",
    "\n",
    "    def _sample_negatives(self, user, num):\n",
    "        pos_items = self.train_user_items.get(user, set())\n",
    "        candidates = list(self.items - pos_items)\n",
    "        return random.sample(candidates, num) if len(candidates) >= num else []\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.T):\n",
    "            total_loss = 0.0\n",
    "            for user in tqdm(self.train_user_items, desc=f'Epoch {epoch+1}'):\n",
    "                pos_items = self.train_user_items[user]\n",
    "                for i in pos_items:\n",
    "                    A_u = self._sample_negatives(user, self.p)\n",
    "                    if not A_u:\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate U_u^{-i}\n",
    "                    items_minus_i = [item for item in pos_items if item != i]\n",
    "                    len_minus_i = len(items_minus_i)\n",
    "                    sum_W_minus_i = np.sum(self.W[items_minus_i], axis=0) if items_minus_i else 0\n",
    "                    U_u_minus_i = sum_W_minus_i / (len_minus_i ** self.alpha) if len_minus_i > 0 else 0\n",
    "                    r_ui = self.bi[i] + np.dot(U_u_minus_i, self.V[i])\n",
    "                    \n",
    "                    # Calculate U_u\n",
    "                    len_total = len(pos_items)\n",
    "                    sum_W_total = np.sum(self.W[list(pos_items)], axis=0)\n",
    "                    U_u = sum_W_total / (len_total ** self.alpha) if len_total > 0 else 0\n",
    "                    \n",
    "                    sum_e = 0.0\n",
    "                    sum_grad_Vi = np.zeros(self.d)\n",
    "                    \n",
    "                    for j in A_u:\n",
    "                        r_uj = self.bi[j] + np.dot(U_u, self.V[j])\n",
    "                        e = (1 - (r_ui - r_uj)) / len(A_u)\n",
    "                        \n",
    "                        # Update j parameters\n",
    "                        self.bi[j] -= self.learning_rate * (e + self.beta_v * self.bi[j])\n",
    "                        grad_Vj = e * U_u + self.alpha_v * self.V[j]\n",
    "                        self.V[j] -= self.learning_rate * grad_Vj\n",
    "                        \n",
    "                        sum_e += e\n",
    "                        sum_grad_Vi += (-e) * U_u_minus_i\n",
    "                        \n",
    "                        # Update W parameters\n",
    "                        term_i_prime = (-e) * (self.V[j] / (len_minus_i ** self.alpha) - \n",
    "                                             self.V[j] / (len_total ** self.alpha))\n",
    "                        if items_minus_i:\n",
    "                            self.W[items_minus_i] -= self.learning_rate * (term_i_prime + \n",
    "                                                                          self.alpha_w * self.W[items_minus_i])\n",
    "                        term_i = (-e) * (-self.V[j] / (len_total ** self.alpha))\n",
    "                        self.W[i] -= self.learning_rate * (term_i + self.alpha_w * self.W[i])\n",
    "                    \n",
    "                    # Update i parameters\n",
    "                    self.bi[i] -= self.learning_rate * ((-sum_e) + self.beta_v * self.bi[i])\n",
    "                    grad_Vi = sum_grad_Vi + self.alpha_v * self.V[i]\n",
    "                    self.V[i] -= self.learning_rate * grad_Vi\n",
    "                    \n",
    "                    total_loss += (1 - (r_ui - np.mean([r_uj for j in A_u]))**2\n",
    "            \n",
    "            print(f\"Average Loss: {total_loss/len(self.train_user_items):.4f}\")\n",
    "\n",
    "    def test(self, K=5):\n",
    "        hits = 0\n",
    "        total_rec = 0\n",
    "        total_relevant = 0\n",
    "        \n",
    "        for user in self.test_user_items:\n",
    "            pos_items = self.test_user_items[user]\n",
    "            if not pos_items:\n",
    "                continue\n",
    "                \n",
    "            # Calculate U_u\n",
    "            train_items = self.train_user_items.get(user, set())\n",
    "            len_total = len(train_items)\n",
    "            if len_total == 0:\n",
    "                continue\n",
    "                \n",
    "            sum_W = np.sum(self.W[list(train_items)], axis=0)\n",
    "            U_u = sum_W / (len_total ** self.alpha)\n",
    "            \n",
    "            # Generate scores\n",
    "            scores = []\n",
    "            for item in self.items - train_items:\n",
    "                score = self.bi[item] + np.dot(U_u, self.V[item])\n",
    "                scores.append( (item, score) )\n",
    "            \n",
    "            # Get top-K\n",
    "            scores.sort(key=lambda x: -x[1])\n",
    "            top_items = [item for item, _ in scores[:K]]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            hits += len(set(top_items) & pos_items)\n",
    "            total_rec += K\n",
    "            total_relevant += len(pos_items)\n",
    "        \n",
    "        precision = hits / total_rec if total_rec > 0 else 0\n",
    "        recall = hits / total_relevant if total_relevant > 0 else 0\n",
    "        print(f\"Precision@{K}: {precision:.4f}\")\n",
    "        print(f\"Recall@{K}: {recall:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    model = FISM_auc(r\"E:\\datasets\\ml-100k\\u1.base\", r\"E:\\datasets\\ml-100k\\u1.test\")\n",
    "    model.train()\n",
    "    model.test()\n",
    "    print(f\"Total time: {time.time()-start:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
