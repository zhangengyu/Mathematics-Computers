{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CF\n",
    "- I_u是一组由用户u评级的项目;\n",
    "- I_w是一组由用户w评级的项目;\n",
    "- U_j是一组给项目j进行评分的用户;\n",
    "#### 基于用户的协同过滤\n",
    "- 相似度的度量：用户u和用户w之间的Pearson相关系数（PCC）:\n",
    "$\\mathbf{s}_{wu}=\\frac{\\sum_{k\\in\\mathcal{I}_w\\cap\\mathcal{I}_u}(r_{uk}-\\bar{r}_u)(r_{wk}-\\bar{r}_w)}{\\sqrt{\\sum_{k\\in\\mathcal{I}_w\\cap\\mathcal{I}_u}(r_{uk}-\\bar{r}_u)^2}\\sqrt{\\sum_{k\\in\\mathcal{I}_w\\cap\\mathcal{I}_u}(r_{wk}-\\bar{r}_w)^2}}$\n",
    "其中，−1 ≤ s_wu ≤ 1.\n",
    "- Top-K most nearest neighbors：\n",
    "  - Obtain the neighbors of user u where s_wu = 0, i.e., N_u\n",
    "    - In practice, we usually use a large N_u as candidate users (instead of\n",
    "all the neighbors) due to the high space cost\n",
    "  - Obtain a set of top-K nearest neighbors of user u from U_j ∩ N_u (when estimating the rating of ˆruj), i.e., N^j_u ⊆ U_j ∩ N_u with |N^j_u| = K.\n",
    "- 预测公式：$\\hat{r}_{uj}=\\bar{r}_{u}+\\frac{\\sum_{w\\in\\mathcal{N}_{u}^{j}}s_{wu}(r_{wj}-\\bar{r}_{w})}{\\sum_{w\\in\\mathcal{N}_{u}^{j}}s_{wu}}$；\n",
    "有时，我们会使用以下的预测规则，$\\hat{r}_{uj}=\\bar{r}_{u}+\\frac{\\sum_{{w\\in\\mathcal{N}_{u}^{j}}}s_{wu}(r_{wj}-\\bar{r}_{w})}{\\sum_{{w\\in\\mathcal{N}_{u}^{j}}}|s_{wu}|}$.\n",
    "当N^j_u = ∅默认值为¯ru.\n",
    "#### 基于物品的协同过滤\n",
    "- 相似度的度量：$s_{kj}=\\frac{\\sum_{{u\\in\\mathcal{U}_{k}\\cap\\mathcal{U}_{j}}}(r_{uk}-\\bar{r}_{u})(r_{uj}-\\bar{r}_{u})}{\\sqrt{\\sum_{{u\\in\\mathcal{U}_{k}\\cap\\mathcal{U}_{j}}}(r_{uk}-\\bar{r}_{u})^{2}}\\sqrt{\\sum_{{u\\in\\mathcal{U}_{k}\\cap\\mathcal{U}_{j}}}(r_{uj}-\\bar{r}_{u})^{2}}}$。\n",
    "- Top-K most nearest neighbors\n",
    "  -  Obtain the neighbors of item j where s_kj ！= 0, i.e., N_j;\n",
    "     -  In practice, we usually use a large N_j as candidate items (instead of all the neighbors) due to the high space cost\n",
    "  -  Obtain the items rated by user u, i.e., I_u\n",
    "  -  Obtain a set of top-K nearest neighbors of item j from I_u ∩ N_j (when estimating the rating of ˆr_uj), i.e., N_ju ⊆ I_u ∩ N_j with |N^u_j| = K\n",
    "  -  K is a parameter needs to be tuned, e.g., K ∈ {20, 30, 40, 50, 100}\n",
    "- 预测公式：\n",
    "$\\hat{r}_{uj}=\\frac{\\sum_{k\\in\\mathcal{N}_j^u}s_{kj}r_{uk}}{\\sum_{k\\in\\mathcal{N}_j^u}s_{kj}}$\n",
    "Notes:\n",
    "the default value is ¯ru if N^u_j = ∅\n",
    "N^u_j is dependent on both item j and user u  \n",
    "#### 混合协同过滤\n",
    "- 在混合协同过滤中，将UCF的预测评分与ICF的预测评分相结合，得到混合的预测评分：\n",
    "$\\hat{r}_{uj}=\\lambda^{UCF}\\hat{r}_{uj}^{UCF}+(1-\\lambda^{UCF})\\hat{r}_{uj}^{ICF}$\n",
    "where 0 ≤ $λ^{UCF}$ ≤ 1 is a tradeoff parameter.\n",
    "#### 注意事项\n",
    "if ˆr_ui > 5, set it as 5;\n",
    "if ˆr_ui < 1, set it as 1\n",
    "#### 评价指标\n",
    "- MAE：\n",
    "$MAE=\\sum_{{(u,i,r_{ui})\\in\\mathcal{R}^{te}}}|r_{ui}-\\hat{r}_{ui}|/|\\mathcal{R}^{te}|$\n",
    "- RMSE：\n",
    "$RMSE=\\sqrt{\\sum_{{(u,i,r_{ui})\\in\\mathcal{R}^{te}}}(r_{ui}-\\hat{r}_{ui})^{2}/|\\mathcal{R}^{te}|}$\n",
    "#### 代码实现\n",
    "在本问题中，K取为50，$λ^{UCF}$取0.5。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCF_MSE=0.9561858486943877\n",
      "UCF_MAE=0.7492020495442102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1650/1650 [01:30<00:00, 18.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICF_RMSE=1.0129494935581418\n",
      "ICF_MAE=0.7953087606829314\n",
      "Hybrid_CF_RMSE=1.002138013931533\n",
      "Hybrid_CF_MAE=0.7860205899420444\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "# 每个用户的评分的平均值\n",
    "u_r_averages = {}\n",
    "# 每个用户评分过的电影ID\n",
    "u_r_items = {}\n",
    "#每个电影评分过的用户id列表，读取数据\n",
    "item_rating_lists = {}\n",
    "all_data = pd.read_csv(\"E:/ml-100k/ml-100k/u.data\",sep='\\t',names=['uid','iid','rating','time'])\n",
    "train_data = pd.read_csv(\"E:/ml-100k/ml-100k/u1.base\",sep='\\t',names=['uid','iid','rating','time'])\n",
    "test_data = pd.read_csv(\"E:/ml-100k/ml-100k/u1.test\",sep='\\t',names=['uid','iid','rating','time'])\n",
    "\n",
    "for i,group in train_data.groupby('uid'):\n",
    "    u_r_averages[i] = group['rating'].mean()# 算均值\n",
    "    u_r_items[i] = set(group['iid'])\n",
    "# 建立倒排表：电影->用户\n",
    "for i,group in train_data.groupby('iid'):\n",
    "    item_rating_lists[i] = set(group['uid'])\n",
    "\n",
    "ratings = {}\n",
    "for i,group in train_data.groupby('uid'):\n",
    "    rating_dict = dict(zip(group['iid'], group['rating']))\n",
    "    ratings[i] = rating_dict\n",
    "\n",
    "rating_arr = [[0]*1682 for i in range(943)]\n",
    "for i,group in train_data.groupby('uid'):\n",
    "    arr = zip(group['iid'], group['rating'])\n",
    "    for pair in arr:\n",
    "        rating_arr[i-1][pair[0]-1] = pair[1]\n",
    "test_iid_set = set(test_data['iid'])\n",
    "train_iid_set = set(train_data['iid'])\n",
    "\n",
    "new_item_set = test_iid_set - train_iid_set\n",
    "\n",
    "# 示例数据\n",
    "x = np.array(rating_arr[0])\n",
    "y = np.array(rating_arr[1])\n",
    " \n",
    "# 计算皮尔逊相关系数\n",
    "coef, p_value = pearsonr(x,y)\n",
    " \n",
    "#print(f\"皮尔逊相关系数: {coef}, 显著性水平p-value: {p_value}\")\n",
    "\n",
    "similar_pcc = np.corrcoef(rating_arr)\n",
    "'''\n",
    "ratings列表：是评分表， ratings[i][j]表示用户ID=i+1对电影ID=j+1的评分\n",
    "u_r_items字典：每个用户评分过的电影ID\n",
    "u_r_averages字典：每个用户的评分的平均值\n",
    "''' \n",
    "def pcc(ratings, u_r_items, u_r_averages, user_num):\n",
    "    user_set = u_r_averages.keys()\n",
    "    pcc_arr = np.ones((user_num, user_num))\n",
    "    \n",
    "    for uid in tqdm(user_set):\n",
    "        for pair in user_set:\n",
    "            if uid == pair:\n",
    "                continue\n",
    "            if pcc_arr[pair-1][uid-1] != 1:\n",
    "                pcc_arr[uid-1][pair-1] = pcc_arr[pair-1][uid-1]\n",
    "                continue\n",
    "\n",
    "            common_rating_items = u_r_items.get(uid) & u_r_items.get(pair)\n",
    "            if not common_rating_items:\n",
    "                continue  # No common ratings\n",
    "\n",
    "            Numerator, denominator_one, denominator_two = 0, 0, 0\n",
    "            for iid in common_rating_items:\n",
    "                uid_rating = ratings[uid][iid]\n",
    "                pair_rating = ratings[pair][iid]\n",
    "                bias_uid = uid_rating - u_r_averages[uid]\n",
    "                bias_pair = pair_rating - u_r_averages[pair]\n",
    "                \n",
    "                Numerator += bias_uid * bias_pair\n",
    "                denominator_one += bias_uid**2\n",
    "                denominator_two += bias_pair**2\n",
    "\n",
    "            denominator_one = math.sqrt(denominator_one)\n",
    "            denominator_two = math.sqrt(denominator_two)\n",
    "\n",
    "            if denominator_one == 0 or denominator_two == 0:\n",
    "                continue\n",
    "            \n",
    "            pcc_value = Numerator / (denominator_one * denominator_two)\n",
    "            pcc_arr[uid-1][pair-1] = pcc_value\n",
    "            \n",
    "    return pcc_arr\n",
    "\n",
    "def ucf_neigh_select(pcc_arr, item_rating_lists, k, uid, iid):\n",
    "    recList = {}\n",
    "    item_rated_users = item_rating_lists.get(iid, set())\n",
    "    pcc_non_zero = {index + 1 for index, value in enumerate(pcc_arr[uid-1]) if value != 0}\n",
    "    pcc_non_zero.discard(uid)\n",
    "\n",
    "    common_users = item_rated_users & pcc_non_zero\n",
    "    if not common_users:\n",
    "        return {}\n",
    "\n",
    "    for i in common_users:\n",
    "        small_id = min(uid, i)\n",
    "        big_id = max(uid, i)\n",
    "        recList[i] = pcc_arr[small_id-1][big_id-1]\n",
    "\n",
    "    topK = dict(sorted(recList.items(), key=lambda x: x[1], reverse=True)[:k])\n",
    "    return topK\n",
    "\n",
    "    \n",
    "def testUCF(path, pcc_arr, item_rating_lists, k):\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    with open(path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            predict_u_r = 0\n",
    "            user_bias = 0\n",
    "            sum_pcc = 0\n",
    "            uid = int(lines[i].split()[0])\n",
    "            iid = int(lines[i].split()[1])\n",
    "            # 冷启动处理，测试集中的物品在训练集没有出现过，则跳过该物品的评分预测\n",
    "            if iid in new_item_set:\n",
    "                continue\n",
    "            target_rating = int(lines[i].split()[2])\n",
    "            user_rating_average = u_r_averages.get(uid)\n",
    "            \n",
    "            top_k_dict = ucf_neigh_select(pcc_arr, item_rating_lists, k, uid, iid)\n",
    "            if len(top_k_dict) == 0:\n",
    "                predict_u_r = user_rating_average\n",
    "            else:\n",
    "                for userId,pcc in top_k_dict.items():\n",
    "                    user_bias += ((ratings.get(userId).get(iid) - u_r_averages.get(userId)) * pcc)\n",
    "                    sum_pcc += abs(pcc)\n",
    "                user_bias = user_bias / (sum_pcc)\n",
    "                predict_u_r = user_rating_average + user_bias\n",
    "            # 后处理过程\n",
    "            if predict_u_r > 5:\n",
    "                predict_u_r = 5\n",
    "            if predict_u_r < 1:\n",
    "                predict_u_r = 1\n",
    "            \n",
    "            predicts.append(predict_u_r)\n",
    "            targets.append(target_rating)\n",
    "    return targets,predicts\n",
    "# similar_arr = pcc(ratings, u_r_items, u_r_averages,943)\n",
    "similar_arr = np.corrcoef(rating_arr)\n",
    "a,b = testUCF(\"E:/ml-100k/ml-100k/u1.test\", similar_arr, item_rating_lists, 50)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "print('UCF_RMSE={}'.format(math.sqrt(mean_squared_error(a,b))))\n",
    "print('UCF_MAE={}'.format(mean_absolute_error(a,b)))\n",
    "\n",
    "'''\n",
    "ratings列表：是评分表， ratings[i][j]表示用户ID=i+1对电影ID=j+1的评分\n",
    "item_rating_lists：每个电影评分过的用户ID\n",
    "u_r_averages字典：每个用户的评分的平均值\n",
    "''' \n",
    "def acs(ratings, item_rating_lists, u_r_averages, item_num):\n",
    "    iid_set = item_rating_lists.keys()\n",
    "    acs_arr = [[1]*item_num for _ in range(item_num)]\n",
    "    for k in tqdm(iid_set):\n",
    "        for j in iid_set:\n",
    "            if k == j:\n",
    "                continue\n",
    "            # 如果另一对已经做过，则不用去做了    \n",
    "            if acs_arr[j-1][k-1] != 1:\n",
    "                acs_arr[k-1][j-1] = acs_arr[j-1][k-1]\n",
    "                continue\n",
    "            numerator = 0\n",
    "            denominator_one = 0\n",
    "            denominator_two = 0\n",
    "            common_rating_users = item_rating_lists.get(k) & item_rating_lists.get(j)\n",
    "            for uid in common_rating_users:\n",
    "                bias_k = ratings.get(uid).get(k) - u_r_averages.get(uid)\n",
    "                bias_j = ratings.get(uid).get(j) - u_r_averages.get(uid)\n",
    "                numerator += round(bias_k * bias_j,4)\n",
    "                denominator_one += round(bias_k * bias_k,4)\n",
    "                denominator_two += round(bias_j * bias_j,4)\n",
    "            denominator_one = math.sqrt(denominator_one)\n",
    "            denominator_two = math.sqrt(denominator_two)\n",
    "            if denominator_one == 0 or denominator_two == 0:\n",
    "                    continue\n",
    "            acs_value = numerator / round(denominator_one * denominator_two,4)\n",
    "            # acs 值在[-1，1]区间            \n",
    "            if abs(acs_value) > 1:\n",
    "                acs_value = int(acs_value)\n",
    "            acs_arr[k-1][j-1] = acs_value\n",
    "    return acs_arr\n",
    "\n",
    "'''\n",
    "acs_arr 列表：acs_arr[k][j] 表示物品k与物品j的相关系数，只记录了上半三角，必须从小索引先开始k<j\n",
    "item_rating_lists字典：item_rating_lists[i]表示对电影ID=i评分过的用户ID集合\n",
    "'''\n",
    "def icf_neigh_select(acs_arr,u_r_items, k, uid, iid):\n",
    "    recList = {}\n",
    "    # 用户评过分的物品\n",
    "    user_rated_items = u_r_items.get(uid)\n",
    "    # 和物品iid的ACS不等于0的物品ID集合，从1开始的\n",
    "    acs_non_zero = set([index+1 for index, value in enumerate(acs_arr[iid-1]) if value != 0])\n",
    "    if user_rated_items == None:\n",
    "        user_rated_items = set()\n",
    "    common_items = user_rated_items & acs_non_zero\n",
    "    if len(common_items)==0:\n",
    "        return dict()\n",
    "    for i in common_items:\n",
    "        # 因为相似度矩阵只保留了上三角，所以要从小的下标开始索引\n",
    "        small_id = min(iid,i)\n",
    "        big_id = max(iid,i)\n",
    "        recList[i] = acs_arr[small_id-1][big_id-1]\n",
    "    topK = dict(sorted(recList.items(), key=lambda x: x[1],reverse = True))\n",
    "    if len(topK) > k:\n",
    "        return dict(list(topK.items())[:k])\n",
    "    else:\n",
    "        return topK\n",
    "def testICF(path, acs_arr, u_r_items, k):\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    with open(path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            predict_u_r = 0\n",
    "            user_bias = 0\n",
    "            sum_acs = 0\n",
    "            uid = int(lines[i].split()[0])\n",
    "            iid = int(lines[i].split()[1])\n",
    "#             if iid in setC:\n",
    "#                 continue\n",
    "            target_rating = int(lines[i].split()[2])\n",
    "            user_rating_average = u_r_averages.get(uid)\n",
    "            \n",
    "            top_k_dict = icf_neigh_select(acs_arr, u_r_items, k, uid, iid)\n",
    "            if len(top_k_dict) == 0:\n",
    "                predict_u_r = user_rating_average\n",
    "            else:\n",
    "                for item_id,acs in top_k_dict.items():\n",
    "                    user_bias += ratings.get(uid).get(item_id) * acs\n",
    "                    sum_acs += acs\n",
    "                # uid=130 iid=1273 top_k_dict = {1278: 1.0, 1279: -1.0}\n",
    "                if sum_acs == 0:\n",
    "                    print(uid,iid,top_k_dict)\n",
    "                    continue\n",
    "                user_bias = user_bias / (sum_acs)\n",
    "                predict_u_r = user_bias\n",
    "            # 后处理过程\n",
    "            if predict_u_r > 5:\n",
    "                predict_u_r = 5\n",
    "            if predict_u_r < 1:\n",
    "                predict_u_r = 1\n",
    "            \n",
    "            predicts.append(predict_u_r)\n",
    "            targets.append(target_rating)\n",
    "    return targets,predicts\n",
    "similar_arr = acs(ratings, item_rating_lists, u_r_averages, 1682)\n",
    "# a,b = testICF(\"datasets/ml-100k/u1.test\", similar_arr, u_r_items, 50)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# a=[[1,3,2],[2,2,1]]\n",
    "transposed_matrix = list(map(list, zip(*rating_arr)))\n",
    "result = cosine_similarity(transposed_matrix)\n",
    "\n",
    "similar_arr[0][0]\n",
    "import numpy as np\n",
    "vec1 = np.array(transposed_matrix[0])\n",
    "vec2 = np.array(transposed_matrix[1])\n",
    "\n",
    "cos_sim = vec1.dot(vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "#print(cos_sim)\n",
    "\n",
    "a,b = testICF(\"E:/ml-100k/ml-100k/u1.test\", result, u_r_items, 50)\n",
    "\n",
    "print('ICF_RMSE={}'.format(math.sqrt(mean_squared_error(a,b))))\n",
    "print('ICF_MAE={}'.format(mean_absolute_error(a,b)))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# 定义Hybrid CF的测试函数\n",
    "def testHybridCF(path, ucf_arr, icf_arr, item_rating_lists, u_r_items, k, lambda_val=0.5):\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    with open(path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            uid = int(lines[i].split()[0])\n",
    "            iid = int(lines[i].split()[1])\n",
    "            target_rating = int(lines[i].split()[2])\n",
    "            user_rating_average = u_r_averages.get(uid)\n",
    "            \n",
    "            # 处理UCF部分\n",
    "            top_k_ucf_dict = ucf_neigh_select(ucf_arr, item_rating_lists, k, uid, iid)\n",
    "            predict_u_r_ucf = user_rating_average\n",
    "            user_bias_ucf = 0\n",
    "            sum_pcc = 0\n",
    "            if len(top_k_ucf_dict) != 0:\n",
    "                for userId, pcc in top_k_ucf_dict.items():\n",
    "                    user_bias_ucf += ((ratings.get(userId).get(iid) - u_r_averages.get(userId)) * pcc)\n",
    "                    sum_pcc += abs(pcc)\n",
    "                if sum_pcc != 0:\n",
    "                    user_bias_ucf = user_bias_ucf / sum_pcc\n",
    "                    predict_u_r_ucf += user_bias_ucf\n",
    "            \n",
    "            # 处理ICF部分\n",
    "            top_k_icf_dict = icf_neigh_select(icf_arr, u_r_items, k, uid, iid)\n",
    "            predict_u_r_icf = 0\n",
    "            user_bias_icf = 0\n",
    "            sum_acs = 0\n",
    "            if len(top_k_icf_dict) != 0:\n",
    "                for item_id, acs in top_k_icf_dict.items():\n",
    "                    user_bias_icf += ratings.get(uid).get(item_id) * acs\n",
    "                    sum_acs += acs\n",
    "                if sum_acs != 0:\n",
    "                    user_bias_icf = user_bias_icf / sum_acs\n",
    "                    predict_u_r_icf += user_bias_icf\n",
    "\n",
    "            # 计算混合预测评分\n",
    "            predict_u_r_hybrid = lambda_val * predict_u_r_ucf + (1 - lambda_val) * predict_u_r_icf\n",
    "\n",
    "            # 后处理过程，限制评分范围在[1, 5]之间\n",
    "            if predict_u_r_hybrid > 5:\n",
    "                predict_u_r_hybrid = 5\n",
    "            if predict_u_r_hybrid < 1:\n",
    "                predict_u_r_hybrid = 1\n",
    "\n",
    "            predicts.append(predict_u_r_hybrid)\n",
    "            targets.append(target_rating)\n",
    "\n",
    "    return targets, predicts\n",
    "\n",
    "# 使用Hybrid CF进行预测，并计算RMSE和MAE\n",
    "lambda_val = 0.5  # 设置混合模型的权重\n",
    "a, b = testHybridCF(\"E:/ml-100k/ml-100k/u1.test\", similar_arr, result, item_rating_lists, u_r_items, 50, lambda_val)\n",
    "print('Hybrid_CF_RMSE={}'.format(math.sqrt(mean_squared_error(a, b))))\n",
    "print('Hybrid_CF_MAE={}'.format(mean_absolute_error(a, b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1650 is out of bounds for axis 0 with size 1650",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m uid, group \u001b[38;5;129;01min\u001b[39;00m train_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muid\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iid, rating \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miid\u001b[39m\u001b[38;5;124m'\u001b[39m], group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m---> 37\u001b[0m         rating_arr[uid \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m][iid \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m rating\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# 获取新物品集合（测试集中有而训练集中没有的物品）\u001b[39;00m\n\u001b[0;32m     40\u001b[0m test_iid_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miid\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1650 is out of bounds for axis 0 with size 1650"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 读取数据\n",
    "all_data = pd.read_csv(\"E:/ml-100k/ml-100k/u.data\", sep='\\t', names=['uid', 'iid', 'rating', 'time'])\n",
    "train_data = pd.read_csv(\"E:/ml-100k/ml-100k/u1.base\", sep='\\t', names=['uid', 'iid', 'rating', 'time'])\n",
    "test_data = pd.read_csv(\"E:/ml-100k/ml-100k/u1.test\", sep='\\t', names=['uid', 'iid', 'rating', 'time'])\n",
    "\n",
    "# 初始化变量\n",
    "u_r_averages = {}    # 每个用户的平均评分\n",
    "u_r_items = {}       # 每个用户评分过的物品ID集合\n",
    "item_rating_lists = {}  # 每个物品被评分的用户ID集合\n",
    "ratings = {}         # 用户对物品的评分字典\n",
    "\n",
    "# 处理训练数据\n",
    "for uid, group in train_data.groupby('uid'):\n",
    "    u_r_averages[uid] = group['rating'].mean()\n",
    "    u_r_items[uid] = set(group['iid'])\n",
    "    ratings[uid] = dict(zip(group['iid'], group['rating']))\n",
    "\n",
    "# 建立物品到用户的倒排表\n",
    "for iid, group in train_data.groupby('iid'):\n",
    "    item_rating_lists[iid] = set(group['uid'])\n",
    "\n",
    "# 创建用户-物品评分矩阵\n",
    "user_num = train_data['uid'].nunique()\n",
    "item_num = train_data['iid'].nunique()\n",
    "rating_arr = np.zeros((user_num, item_num))\n",
    "for uid, group in train_data.groupby('uid'):\n",
    "    for iid, rating in zip(group['iid'], group['rating']):\n",
    "        rating_arr[uid - 1][iid - 1] = rating\n",
    "\n",
    "# 获取新物品集合（测试集中有而训练集中没有的物品）\n",
    "test_iid_set = set(test_data['iid'])\n",
    "train_iid_set = set(train_data['iid'])\n",
    "new_item_set = test_iid_set - train_iid_set\n",
    "\n",
    "# 定义计算PCC相似度的函数\n",
    "def pcc(ratings, u_r_items, u_r_averages, user_num):\n",
    "    user_set = u_r_averages.keys()\n",
    "    pcc_arr = np.ones((user_num, user_num))\n",
    "    for uid in tqdm(user_set):\n",
    "        for pair in user_set:\n",
    "            if uid >= pair:\n",
    "                continue\n",
    "            common_items = u_r_items[uid] & u_r_items[pair]\n",
    "            if not common_items:\n",
    "                pcc_arr[uid - 1][pair - 1] = 0\n",
    "                continue\n",
    "            numerator, denom_uid, denom_pair = 0, 0, 0\n",
    "            for iid in common_items:\n",
    "                uid_rating = ratings[uid][iid]\n",
    "                pair_rating = ratings[pair][iid]\n",
    "                bias_uid = uid_rating - u_r_averages[uid]\n",
    "                bias_pair = pair_rating - u_r_averages[pair]\n",
    "                numerator += bias_uid * bias_pair\n",
    "                denom_uid += bias_uid ** 2\n",
    "                denom_pair += bias_pair ** 2\n",
    "            denominator = math.sqrt(denom_uid) * math.sqrt(denom_pair)\n",
    "            if denominator == 0:\n",
    "                pcc_value = 0\n",
    "            else:\n",
    "                pcc_value = numerator / denominator\n",
    "            pcc_arr[uid - 1][pair - 1] = pcc_value\n",
    "            pcc_arr[pair - 1][uid - 1] = pcc_value  # 对称矩阵\n",
    "    return pcc_arr\n",
    "\n",
    "# 定义UCF的邻居选择函数\n",
    "def ucf_neigh_select(pcc_arr, item_rating_lists, k, uid, iid):\n",
    "    recList = {}\n",
    "    item_rated_users = item_rating_lists.get(iid, set())\n",
    "    if uid in item_rated_users:\n",
    "        item_rated_users.remove(uid)\n",
    "    common_users = item_rated_users\n",
    "    if not common_users:\n",
    "        return {}\n",
    "    for neighbor_uid in common_users:\n",
    "        similarity = pcc_arr[uid - 1][neighbor_uid - 1]\n",
    "        if similarity > 0:\n",
    "            recList[neighbor_uid] = similarity\n",
    "    topK = dict(sorted(recList.items(), key=lambda x: x[1], reverse=True)[:k])\n",
    "    return topK\n",
    "\n",
    "# 定义UCF的测试函数\n",
    "def testUCF(test_data, pcc_arr, item_rating_lists, k):\n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    for idx, row in test_data.iterrows():\n",
    "        uid = row['uid']\n",
    "        iid = row['iid']\n",
    "        target_rating = row['rating']\n",
    "        # 冷启动处理\n",
    "        if iid in new_item_set:\n",
    "            continue\n",
    "        user_rating_average = u_r_averages.get(uid, 0)\n",
    "        top_k_dict = ucf_neigh_select(pcc_arr, item_rating_lists, k, uid, iid)\n",
    "        if not top_k_dict:\n",
    "            predict_u_r = user_rating_average\n",
    "        else:\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "            for neighbor_uid, sim in top_k_dict.items():\n",
    "                neighbor_rating = ratings[neighbor_uid].get(iid, 0)\n",
    "                neighbor_avg = u_r_averages.get(neighbor_uid, 0)\n",
    "                numerator += sim * (neighbor_rating - neighbor_avg)\n",
    "                denominator += abs(sim)\n",
    "            if denominator == 0:\n",
    "                predict_u_r = user_rating_average\n",
    "            else:\n",
    "                predict_u_r = user_rating_average + numerator / denominator\n",
    "        # 后处理\n",
    "        predict_u_r = max(min(predict_u_r, 5), 1)\n",
    "        user_ids.append(uid)\n",
    "        item_ids.append(iid)\n",
    "        predicts.append(predict_u_r)\n",
    "        targets.append(target_rating)\n",
    "    return user_ids, item_ids, targets, predicts\n",
    "\n",
    "# 计算用户相似度矩阵\n",
    "print(\"计算用户相似度矩阵...\")\n",
    "similar_arr = pcc(ratings, u_r_items, u_r_averages, user_num)\n",
    "\n",
    "# 测试UCF\n",
    "print(\"测试UCF...\")\n",
    "user_ids_ucf, item_ids_ucf, targets_ucf, predicts_ucf = testUCF(test_data, similar_arr, item_rating_lists, k=50)\n",
    "rmse_ucf = math.sqrt(mean_squared_error(targets_ucf, predicts_ucf))\n",
    "mae_ucf = mean_absolute_error(targets_ucf, predicts_ucf)\n",
    "print(f'UCF RMSE={rmse_ucf}')\n",
    "print(f'UCF MAE={mae_ucf}')\n",
    "\n",
    "# 定义ACS相似度计算函数\n",
    "def acs(ratings, item_rating_lists, u_r_averages, item_num):\n",
    "    iid_set = item_rating_lists.keys()\n",
    "    acs_arr = np.ones((item_num, item_num))\n",
    "    for iid in tqdm(iid_set):\n",
    "        for pair_iid in iid_set:\n",
    "            if iid >= pair_iid:\n",
    "                continue\n",
    "            common_users = item_rating_lists[iid] & item_rating_lists[pair_iid]\n",
    "            if not common_users:\n",
    "                acs_arr[iid - 1][pair_iid - 1] = 0\n",
    "                continue\n",
    "            numerator, denom_iid, denom_pair = 0, 0, 0\n",
    "            for uid in common_users:\n",
    "                rating_iid = ratings[uid][iid]\n",
    "                rating_pair = ratings[uid][pair_iid]\n",
    "                avg_uid = u_r_averages[uid]\n",
    "                bias_iid = rating_iid - avg_uid\n",
    "                bias_pair = rating_pair - avg_uid\n",
    "                numerator += bias_iid * bias_pair\n",
    "                denom_iid += bias_iid ** 2\n",
    "                denom_pair += bias_pair ** 2\n",
    "            denominator = math.sqrt(denom_iid) * math.sqrt(denom_pair)\n",
    "            if denominator == 0:\n",
    "                acs_value = 0\n",
    "            else:\n",
    "                acs_value = numerator / denominator\n",
    "            acs_arr[iid - 1][pair_iid - 1] = acs_value\n",
    "            acs_arr[pair_iid - 1][iid - 1] = acs_value  # 对称矩阵\n",
    "    return acs_arr\n",
    "\n",
    "# 定义ICF的邻居选择函数\n",
    "def icf_neigh_select(acs_arr, u_r_items, k, uid, iid):\n",
    "    recList = {}\n",
    "    user_rated_items = u_r_items.get(uid, set())\n",
    "    if not user_rated_items:\n",
    "        return {}\n",
    "    for item_id in user_rated_items:\n",
    "        similarity = acs_arr[iid - 1][item_id - 1]\n",
    "        if similarity > 0:\n",
    "            recList[item_id] = similarity\n",
    "    topK = dict(sorted(recList.items(), key=lambda x: x[1], reverse=True)[:k])\n",
    "    return topK\n",
    "\n",
    "# 定义ICF的测试函数\n",
    "def testICF(test_data, acs_arr, u_r_items, k):\n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    for idx, row in test_data.iterrows():\n",
    "        uid = row['uid']\n",
    "        iid = row['iid']\n",
    "        target_rating = row['rating']\n",
    "        # 冷启动处理\n",
    "        if iid in new_item_set:\n",
    "            continue\n",
    "        user_rating_average = u_r_averages.get(uid, 0)\n",
    "        top_k_dict = icf_neigh_select(acs_arr, u_r_items, k, uid, iid)\n",
    "        if not top_k_dict:\n",
    "            predict_u_r = user_rating_average\n",
    "        else:\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "            for item_id, sim in top_k_dict.items():\n",
    "                rating = ratings[uid].get(item_id, 0)\n",
    "                numerator += sim * rating\n",
    "                denominator += abs(sim)\n",
    "            if denominator == 0:\n",
    "                predict_u_r = user_rating_average\n",
    "            else:\n",
    "                predict_u_r = numerator / denominator\n",
    "        # 后处理\n",
    "        predict_u_r = max(min(predict_u_r, 5), 1)\n",
    "        user_ids.append(uid)\n",
    "        item_ids.append(iid)\n",
    "        predicts.append(predict_u_r)\n",
    "        targets.append(target_rating)\n",
    "    return user_ids, item_ids, targets, predicts\n",
    "\n",
    "# 计算物品相似度矩阵\n",
    "print(\"计算物品相似度矩阵...\")\n",
    "# 转置用户-物品评分矩阵\n",
    "transposed_matrix = rating_arr.T\n",
    "# 使用余弦相似度计算物品相似度矩阵\n",
    "acs_arr = cosine_similarity(transposed_matrix)\n",
    "\n",
    "# 测试ICF\n",
    "print(\"测试ICF...\")\n",
    "user_ids_icf, item_ids_icf, targets_icf, predicts_icf = testICF(test_data, acs_arr, u_r_items, k=50)\n",
    "rmse_icf = math.sqrt(mean_squared_error(targets_icf, predicts_icf))\n",
    "mae_icf = mean_absolute_error(targets_icf, predicts_icf)\n",
    "print(f'ICF RMSE={rmse_icf}')\n",
    "print(f'ICF MAE={mae_icf}')\n",
    "\n",
    "# 对齐UCF和ICF的预测结果\n",
    "common_indices = []\n",
    "for idx, (uid_ucf, iid_ucf) in enumerate(zip(user_ids_ucf, item_ids_ucf)):\n",
    "    for jdx, (uid_icf, iid_icf) in enumerate(zip(user_ids_icf, item_ids_icf)):\n",
    "        if uid_ucf == uid_icf and iid_ucf == iid_icf:\n",
    "            common_indices.append((idx, jdx))\n",
    "            break\n",
    "\n",
    "# 提取共同的预测和真实值\n",
    "targets_common = [targets_ucf[idx] for idx, _ in common_indices]\n",
    "predicts_ucf_common = [predicts_ucf[idx] for idx, _ in common_indices]\n",
    "predicts_icf_common = [predicts_icf[jdx] for _, jdx in common_indices]\n",
    "\n",
    "# 计算混合协同过滤的预测\n",
    "lambda_ucf = 0.5  # UCF的权重\n",
    "hybrid_predicts = []\n",
    "for ucf_pred, icf_pred in zip(predicts_ucf_common, predicts_icf_common):\n",
    "    hybrid_pred = lambda_ucf * ucf_pred + (1 - lambda_ucf) * icf_pred\n",
    "    hybrid_pred = max(min(hybrid_pred, 5), 1)\n",
    "    hybrid_predicts.append(hybrid_pred)\n",
    "\n",
    "# 计算混合协同过滤的RMSE和MAE\n",
    "rmse_hybrid = math.sqrt(mean_squared_error(targets_common, hybrid_predicts))\n",
    "mae_hybrid = mean_absolute_error(targets_common, hybrid_predicts)\n",
    "print(f'Hybrid CF RMSE={rmse_hybrid}')\n",
    "print(f'Hybrid CF MAE={mae_hybrid}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "User-based CF RMSE: 1.0098, MAE: 0.8016\n",
      "Item-based CF RMSE: 1.0474, MAE: 0.8257\n",
      "Hybrid CF RMSE: 0.9724, MAE: 0.7785\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise import KNNBasic\n",
    "import numpy as np\n",
    "\n",
    "# 文件路径\n",
    "train_file = 'E:/ml-100k/ml-100k/u1.base'\n",
    "test_file = 'E:/ml-100k/ml-100k/u1.test'\n",
    "\n",
    "# 数据加载\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t', rating_scale=(1, 5))\n",
    "data_train = Dataset.load_from_file(train_file, reader=reader)\n",
    "data_test = Dataset.load_from_file(test_file, reader=reader)\n",
    "\n",
    "# 数据分割\n",
    "trainset = data_train.build_full_trainset()\n",
    "testset = data_test.build_full_trainset().build_testset()\n",
    "\n",
    "# 用户基础协同过滤\n",
    "sim_options_user_based = {'name': 'pearson_baseline', 'user_based': True}\n",
    "algo_user_based = KNNBasic(k=50, sim_options=sim_options_user_based)\n",
    "algo_user_based.fit(trainset)\n",
    "predictions_user_based = algo_user_based.test(testset)\n",
    "\n",
    "# 物品基础协同过滤\n",
    "sim_options_item_based = {'name': 'cosine', 'user_based': False}\n",
    "algo_item_based = KNNBasic(k=50, sim_options=sim_options_item_based)\n",
    "algo_item_based.fit(trainset)\n",
    "predictions_item_based = algo_item_based.test(testset)\n",
    "\n",
    "# 混合模型\n",
    "def hybrid_prediction(predictions_user_based, predictions_item_based, lambda_UCF):\n",
    "    predictions = []\n",
    "    for pred_ub, pred_ib in zip(predictions_user_based, predictions_item_based):\n",
    "        # 获取真实评分\n",
    "        r_ui = pred_ub.r_ui\n",
    "        # 计算混合预测\n",
    "        est = lambda_UCF * pred_ub.est + (1 - lambda_UCF) * pred_ib.est\n",
    "        # 添加到预测列表\n",
    "        predictions.append((pred_ub.uid, pred_ub.iid, r_ui, est, None))\n",
    "    return predictions\n",
    "\n",
    "lambda_UCF = 0.5\n",
    "predictions_hybrid = hybrid_prediction(predictions_user_based, predictions_item_based, lambda_UCF)\n",
    "\n",
    "# 将预测结果转换成Surprise的Predictions格式\n",
    "hybrid_predictions = [\n",
    "    (pred_uid, pred_iid, pred_r_ui, pred_est, None)\n",
    "    for pred_uid, pred_iid, pred_r_ui, pred_est, _ in predictions_hybrid\n",
    "]\n",
    "\n",
    "# 计算RMSE和MAE\n",
    "rmse_user_based = accuracy.rmse(predictions_user_based, verbose=False)\n",
    "mae_user_based = accuracy.mae(predictions_user_based, verbose=False)\n",
    "rmse_item_based = accuracy.rmse(predictions_item_based, verbose=False)\n",
    "mae_item_based = accuracy.mae(predictions_item_based, verbose=False)\n",
    "rmse_hybrid = accuracy.rmse(hybrid_predictions, verbose=False)\n",
    "mae_hybrid = accuracy.mae(hybrid_predictions, verbose=False)\n",
    "\n",
    "print(f'User-based CF RMSE: {rmse_user_based:.4f}, MAE: {mae_user_based:.4f}')\n",
    "print(f'Item-based CF RMSE: {rmse_item_based:.4f}, MAE: {mae_item_based:.4f}')\n",
    "print(f'Hybrid CF RMSE: {rmse_hybrid:.4f}, MAE: {mae_hybrid:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CF\n",
    "#### User-based CF\n",
    "- Users with similar tastes in the past will have similar tastes in the future：User-based CF\n",
    "- $\\circ$ A user will like some similar items to those he liked before：Item-based CF\n",
    "- $\\begin{array}{l}\\bullet\\mathcal{I}_u\\text{ is a set of items rated by user }u\\\\\\\\\\bullet\\mathcal{I}_w\\text{ is a set of items rated by user }w\\\\\\\\\\bullet\\mathcal{U}_j\\text{ is a set of users who rated item }j\\end{array}$\n",
    "- Pearson correlation coefficient (PCC) between user $u$ and user $w$,\n",
    "\n",
    "$$s_{wu}=\\frac{\\sum_{k\\in\\mathcal{I}_w\\cap\\mathcal{I}_u}(r_{uk}-\\bar{r}_u)(r_{wk}-\\bar{r}_w)}{\\sqrt{\\sum_{k\\in\\mathcal{I}_w\\cap\\mathcal{I}_u}(r_{uk}-\\bar{r}_u)^2}\\sqrt{\\sum_{k\\in\\mathcal{I}_w\\cap\\mathcal{I}_u}(r_{wk}-\\bar{r}_w)^2}}$$\n",
    "Notes:\n",
    "$0-1\\leq s_{wu}\\leq1$\n",
    "- Top-K most nearest neighbors\n",
    "  - Step 1. Obtain the neighbors of user $u$ where $\\mathfrak{s}_{wu}\\neq0,\\mathfrak{i.e.,N}_u$\n",
    "    - In practice, we usually use a large $N_u$ as candidate users (instead of all the neighbors) due to the high space cost\n",
    "\n",
    "  - Step 2. Obtain the users who rated item $j$,i.e.,$\\mathcal{U}_j$\n",
    "  - Step 3. Obtain a set of top-K nearest neighbors of user $u$ from $U_j\\cap\\mathcal{N}_u$ (when estimating the rating of $\\hat{r}_uj)$, i.e., $\\mathcal{N}_u^j\\subseteq\\mathcal{U}_j\\cap\\mathcal{N}_u$ with $|\\mathcal{N}_u^j|=K$\n",
    "- Predicted rating of user $u$ on item $j$,\n",
    "\n",
    "$$\\hat{r}_{uj}=\\bar{r}_u+\\frac{\\sum_{w\\in\\mathcal{N}_u^j}s_{wu}(r_{wj}-\\bar{r}_w)}{\\sum_{w\\in\\mathcal{N}_u^j}s_{wu}}$$\n",
    "\n",
    "Notes:\n",
    "\n",
    "- sometimes, we will use the following prediction rule,\n",
    "\n",
    "  $$\\hat{r}_{uj}=\\bar{r}_u+\\frac{\\sum_{w\\in\\mathcal{N}_u^j}s_{wu}(r_{wj}-\\bar{r}_w)}{\\sum_{w\\in\\mathcal{N}_u^j}|s_{wu}|}$$\n",
    "\n",
    "  - the default value is $\\bar{r}_u$ if $\\mathcal{N}_u^j=\\emptyset$\n",
    "\n",
    "  - $ \\mathcal{N}_u^j$ is dependent on both user $u$ and item $j$\n",
    "- $\\begin{array}{l}\\bullet\\mathcal{U}_k\\text{ is a set of users who rated item }k\\\\\\\\\\bullet\\mathcal{U}_j\\text{ is a set of users who rated item }j\\\\\\\\\\bullet\\mathcal{I}_u\\text{ is a set of items rated by user }u\\end{array}$\n",
    "- Adjusted Cosine similarity between item $k$ and item $j$,\n",
    "\n",
    "$$s_{kj}=\\frac{\\sum_{u\\in\\mathcal{U}_k\\cap\\mathcal{U}_j}(r_{uk}-\\bar{r}_u)(r_{uj}-\\bar{r}_u)}{\\sqrt{\\sum_{u\\in\\mathcal{U}_k\\cap\\mathcal{U}_j}(r_{uk}-\\bar{r}_u)^2}\\sqrt{\\sum_{u\\in\\mathcal{U}_k\\cap\\mathcal{U}_j}(r_{uj}-\\bar{r}_u)^2}}$$\n",
    "\n",
    "Notes\n",
    "\n",
    "  - $-1\\leq s_{kj}\\leq1$\n",
    "\n",
    "  - Cosine similarity between item $k$ and item $j$\n",
    "\n",
    "$$s_{kj}=\\frac{\\sum_{u\\in\\mathcal{U}_k\\cap\\mathcal{U}_j}r_{uk}r_{uj}}{\\sqrt{\\sum_{u\\in\\mathcal{U}_k\\cap\\mathcal{U}_j}r_{uk}^2}\\sqrt{\\sum_{u\\in\\mathcal{U}_k\\cap\\mathcal{U}_j}r_{uj}^2}}$$\n",
    "#### Item-based CF\n",
    "- Similarity threshold:\n",
    "\n",
    "Top-K most nearest neighbors\n",
    "\n",
    "  -  Step 1. Obtain the neighbors of item $j$ where s$_kj\\neq0$,i.e., $\\mathcal{N}_j$\n",
    "\n",
    "     - In practice, we usually use a large $\\mathcal{N}_j$ as candidate items (instead of\n",
    "\n",
    "all the neighbors) due to the high space cost\n",
    "\n",
    "  - Step 2. Obtain the items rated by user $u$, i.e., $I_u$\n",
    "\n",
    "  - Step 3. Obtain a set of top-$K$ nearest neighbors of item $j$ from\n",
    "$\\mathcal{I}_u\\cap\\mathcal{N}_j$ (when estimating the rating of $\\hat{r}_uj)$, i.e., $\\mathcal{N}_j^u\\subseteq\\mathcal{I}_u\\cap\\mathcal{N}_j$ with\n",
    "$|\\tilde{\\mathcal{N}}_j^u|=\\dot{K}$\n",
    "\n",
    "  - K is a parameter needs to be tuned, e.g., $K\\in\\{20,30,40,50,100\\}$\n",
    "- Predicted rating of user $u$ on item $j$,\n",
    "\n",
    "$$\\hat{r}_{uj}=\\frac{\\sum_{k\\in\\mathcal{N}_j^u}s_{kj}r_{uk}}{\\sum_{k\\in\\mathcal{N}_j^u}s_{kj}}$$\n",
    "\n",
    "  - $\\mathsf{Notes:}$\n",
    "the default value is $\\bar{r}_u$ if $\\mathcal{N}_j^u=\\emptyset$\n",
    "  - $\\mathcal{N}_j^u$ is dependent on both item $j$ and user $u$\n",
    "#### Hybrid CF\n",
    "- $\\begin{aligned}&\\text{Predicted rating of user }u\\text{ on item }j,\\\\&\\hat{r}_{uj}=\\lambda^{UCF}\\hat{r}_{uj}^{UCF}+(1-\\lambda^{UCF})\\hat{r}_{uj}^{ICF}\\\\\\\\&\\mathrm{where~}0\\leq\\lambda^{UCF}\\leq1\\text{ is a tradeoff parameter.}\\end{aligned}$\n",
    "#### 结果评估\n",
    "Mean Absolute Error (MAE)\n",
    "\n",
    "$$MAE=\\sum_{(u,i,r_{ui})\\in\\mathcal{R}^{te}}|r_{ui}-\\hat{r}_{ui}|/|\\mathcal{R}^{te}|$$\n",
    "\n",
    "\n",
    " Root Mean Square Error (RMSE)\n",
    "\n",
    "$$RMSE=\\sqrt{\\sum_{(u,i,r_{ui})\\in\\mathcal{R}^{te}}(r_{ui}-\\hat{r}_{ui})^2/|\\mathcal{R}^{te}|}$$\n",
    "#### 注意\n",
    "$\\begin{aligned}&\\text{Post-processing for G}=\\{1,2,3,4,5\\}\\\\&\\text{ if }\\hat{r}_{ui}>5,\\text{set it as 5}\\\\&\\text{ if }\\hat{r}_{ui}<1,\\text{set it as 1}\\end{aligned}$\n",
    "#### 结果\n",
    "- Method RMSE MAE\n",
    "- User-based CF 0.9554 0.7480\n",
    "- Item-based CF 0.9901 0.7801\n",
    "- Hybrid CF 0.9562 0.7538"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
